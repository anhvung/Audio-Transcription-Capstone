{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65fb5e6",
   "metadata": {},
   "source": [
    "# Predict on downsampled tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c42c366-22e7-4585-ad0e-ba04020aeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b5cdc6-e6c6-443a-90d2-afcc4af99ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 available cpus\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method, cpu_count\n",
    "set_start_method(\"spawn\")\n",
    "num_cpus = cpu_count()\n",
    "print('{} available cpus'.format(num_cpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c16ae-f2d3-4b7a-a7f1-4302a3bdf3ae",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630dff8-3c70-47b1-96af-03f7b317ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing item: file://./predictions/lr-clean-test-w2v2-base-960h.hf/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr-clean-test-w2v2-base-960h.hf/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr-clean-test-w2v2-base-960h.hf/state.json\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -n -r gs://capstone_datasets/librispeech/test/predictions/* ./predictions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434e50ed-39fe-48da-88bd-502ce82213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.load_from_disk(utils.os.path.join(utils.predictions_path, 'lr-clean-test-w2v2-base-960h.hf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169e2d4-b030-4ae4-b1fa-b36464515671",
   "metadata": {},
   "source": [
    "## 2. Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43af18e0-fc5f-4833-aff4-68dad4790d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564cea75-bfc5-45b2-89db-eb4d4ee94bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling to 8000Hz...\n",
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb836d2ffea4e17bd59a29996ac3903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47208eb30c9042389abddd427201516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f77f936dc45d2b332991becbb832d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6308fa6d0485481ca3eac5ee884eb191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('downsampling to ' + str(ds_rate) + 'Hz...')\n",
    "temp_data = dataset.map(utils.map_to_downsampled, fn_kwargs={\"input_sr\": 16000, \"output_sr\": ds_rate}, num_proc=4, writer_batch_size=50) # decrease writer_batch_size to avoid OOM issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae95d6-6197-4e8e-b38f-60900f45459d",
   "metadata": {},
   "source": [
    "## 4. Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b908ed35-bed9-4d65-b829-620e41ff45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:757: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = utils.load_wav2vec_model(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec84f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing prediction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b263f427d2a7419a97befbde6e34d5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('computing prediction...')\n",
    "temp_data = temp_data.map(utils.map_to_pred, fn_kwargs={\"model\": model, \"tokenizer\": tokenizer}, writer_batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e574269",
   "metadata": {},
   "source": [
    "## 5. Compute WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678aeb74-e1a7-4749-a2f9-79303fd4035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer= 4.2 %.\n"
     ]
    }
   ],
   "source": [
    "wer = utils.wer(temp_data[\"ground_truth\"], temp_data[\"transcription\"])\n",
    "print('wer=', round(100 * wer, 1), '%.')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
