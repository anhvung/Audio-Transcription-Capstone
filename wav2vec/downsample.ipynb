{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65fb5e6",
   "metadata": {},
   "source": [
    "# Predict on downsampled tracks and save to disk/bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c42c366-22e7-4585-ad0e-ba04020aeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b5cdc6-e6c6-443a-90d2-afcc4af99ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 available cpus\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method, cpu_count\n",
    "set_start_method(\"spawn\")\n",
    "num_cpus = cpu_count()\n",
    "print('{} available cpus'.format(num_cpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c16ae-f2d3-4b7a-a7f1-4302a3bdf3ae",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630dff8-3c70-47b1-96af-03f7b317ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing item: file://./predictions/lr-clean-test-w2v2-base-960h.hf/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr-clean-test-w2v2-base-960h.hf/state.json\n",
      "Skipping existing item: file://./predictions/lr-clean-test-w2v2-base-960h.hf/dataset.arrow\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -n -r gs://capstone_datasets/librispeech/test/predictions/* ./predictions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434e50ed-39fe-48da-88bd-502ce82213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.load_from_disk(utils.os.path.join(utils.predictions_path, 'lr-clean-test-w2v2-base-960h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169e2d4-b030-4ae4-b1fa-b36464515671",
   "metadata": {},
   "source": [
    "## 2. Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43af18e0-fc5f-4833-aff4-68dad4790d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following downsampling rate can be changed\n",
    "# we only downsample one rate at a time to avoid OOM issues\n",
    "ds_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564cea75-bfc5-45b2-89db-eb4d4ee94bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling to 8000Hz...\n",
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a71686ea8d4ac88cf74661c203e280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae0f199513147e0be5fc675ccac0d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f03917ae2384f629429588ac03e911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aede0d007e234cfdb76c15bb38afd1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation took 306s\n"
     ]
    }
   ],
   "source": [
    "print('downsampling to ' + str(ds_rate) + 'Hz...')\n",
    "before = time.time()\n",
    "dataset = dataset.map(utils.map_to_downsampled, fn_kwargs={\"input_sr\": 16000, \"output_sr\": ds_rate}, num_proc=num_cpus, writer_batch_size=50) # decrease writer_batch_size to avoid OOM issues\n",
    "print('operation took {}s'.format(round(time.time() - before), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae95d6-6197-4e8e-b38f-60900f45459d",
   "metadata": {},
   "source": [
    "## 3. Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b908ed35-bed9-4d65-b829-620e41ff45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:757: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = utils.load_wav2vec_model(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec84f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing prediction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac246bc7ebd4aa88faacc14317d6278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation took 374s\n"
     ]
    }
   ],
   "source": [
    "print('computing prediction...')\n",
    "before = time.time()\n",
    "dataset = dataset.map(utils.map_to_pred, fn_kwargs={\"model\": model, \"tokenizer\": tokenizer}, writer_batch_size=1000)\n",
    "print('operation took {}s'.format(round(time.time() - before), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9caf83",
   "metadata": {},
   "source": [
    "## 3. Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8faa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(utils.os.path.join(utils.predictions_path, 'lr_clean_test_ds_' + str(ds_rate) + 'Hz_w2v2_base_960h.hf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e574269",
   "metadata": {},
   "source": [
    "## 4. Compute WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678aeb74-e1a7-4749-a2f9-79303fd4035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer= 4.2 %.\n"
     ]
    }
   ],
   "source": [
    "wer = utils.wer(dataset[\"ground_truth\"], dataset[\"transcription\"])\n",
    "print('wer=', round(100 * wer, 1), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec782a0",
   "metadata": {},
   "source": [
    "## 5. Send all downsampled datasets in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811e1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "\\ [21/21 files][  4.9 GiB/  4.9 GiB] 100% Done 130.9 MiB/s ETA 00:00:00         \n",
      "Operation completed over 21 objects/4.9 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -n -r ./predictions/ gs://capstone_datasets/librispeech/test/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
