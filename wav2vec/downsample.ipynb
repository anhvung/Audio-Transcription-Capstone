{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65fb5e6",
   "metadata": {},
   "source": [
    "# Predict on downsampled tracks and save to disk/bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c42c366-22e7-4585-ad0e-ba04020aeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b5cdc6-e6c6-443a-90d2-afcc4af99ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 available cpus\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method, cpu_count\n",
    "set_start_method(\"spawn\")\n",
    "num_cpus = cpu_count()\n",
    "print('{} available cpus'.format(num_cpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c16ae-f2d3-4b7a-a7f1-4302a3bdf3ae",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630dff8-3c70-47b1-96af-03f7b317ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing item: file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_w2v2_base_960h/state.json\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -n -r gs://capstone_datasets/librispeech/test/predictions/* ./predictions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434e50ed-39fe-48da-88bd-502ce82213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.load_from_disk(utils.os.path.join(utils.predictions_path, 'lr_clean_test_w2v2_base_960h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169e2d4-b030-4ae4-b1fa-b36464515671",
   "metadata": {},
   "source": [
    "## 2. Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43af18e0-fc5f-4833-aff4-68dad4790d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following downsampling rate can be changed\n",
    "# we only downsample one rate at a time to avoid OOM issues\n",
    "ds_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564cea75-bfc5-45b2-89db-eb4d4ee94bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling to 8000Hz...\n",
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b226cf12a1400683afcf6711ffd01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542458f20be6490d92b5261015d3edb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fe35110fd1475da2d6a373f42477d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec13d303d8e4419b41d832f74e9fdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 s, sys: 1.2 s, total: 5.01 s\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('downsampling to ' + str(ds_rate) + 'Hz...')\n",
    "dataset = dataset.map(utils.map_to_downsampled, fn_kwargs={\"input_sr\": 16000, \"output_sr\": ds_rate}, num_proc=num_cpus, writer_batch_size=50) # decrease writer_batch_size to avoid OOM issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae95d6-6197-4e8e-b38f-60900f45459d",
   "metadata": {},
   "source": [
    "## 3. Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b908ed35-bed9-4d65-b829-620e41ff45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:757: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = utils.load_wav2vec_model(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec84f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing prediction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78792a0e619644e78eb6c62590a94986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 35s, sys: 36.3 s, total: 6min 12s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('computing prediction...')\n",
    "dataset = dataset.map(utils.map_to_pred, fn_kwargs={\"model\": model, \"tokenizer\": tokenizer}, writer_batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9caf83",
   "metadata": {},
   "source": [
    "## 3. Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8faa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(utils.os.path.join(utils.predictions_path, 'lr_clean_test_ds_' + str(ds_rate) + 'Hz_w2v2_base_960h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec782a0",
   "metadata": {},
   "source": [
    "## 4. Send predictions to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811e1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "\\ [21/21 files][  4.9 GiB/  4.9 GiB] 100% Done 130.9 MiB/s ETA 00:00:00         \n",
      "Operation completed over 21 objects/4.9 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "#!gsutil -m cp -n -r ./predictions/ gs://capstone_datasets/librispeech/test/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
