{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65fb5e6",
   "metadata": {},
   "source": [
    "# Predict on noisy tracks and save to disk/bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c42c366-22e7-4585-ad0e-ba04020aeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b5cdc6-e6c6-443a-90d2-afcc4af99ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 available cpus\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method, cpu_count\n",
    "set_start_method(\"spawn\")\n",
    "num_cpus = cpu_count()\n",
    "print('{} available cpus'.format(num_cpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c16ae-f2d3-4b7a-a7f1-4302a3bdf3ae",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630dff8-3c70-47b1-96af-03f7b317ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing item: file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_w2v2_base_960h/dataset_info.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_w2v2_base_960h/state.json\n",
      "Skipping existing item: file://./predictions/lr_clean_test_w2v2_base_960h/dataset.arrow\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -n -r gs://capstone_datasets/librispeech/test/predictions/* ./predictions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434e50ed-39fe-48da-88bd-502ce82213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.load_from_disk(utils.os.path.join(utils.predictions_path, 'lr_clean_test_w2v2_base_960h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169e2d4-b030-4ae4-b1fa-b36464515671",
   "metadata": {},
   "source": [
    "## 2. Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa3f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_percentage_factor = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564cea75-bfc5-45b2-89db-eb4d4ee94bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding noise...\n",
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebd3f2a852b48ce85930acef7bac37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f37522c4fc64b76a74cff23c01c4505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce516d464cc54a1b80582a72995e8dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c992b11ad02f4de69e9f3d811d3678e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/655 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 564 ms, total: 2.61 s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('adding noise...')\n",
    "dataset = dataset.map(utils.map_to_noisy, fn_kwargs={'sample_rate' : 16000, 'noise_percentage_factor' : noise_percentage_factor, 'noise_type'  : 'white'}, \n",
    "    num_proc=num_cpus, writer_batch_size=300) # decrease writer_batch_size to avoid OOM issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae95d6-6197-4e8e-b38f-60900f45459d",
   "metadata": {},
   "source": [
    "## 3. Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b908ed35-bed9-4d65-b829-620e41ff45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:757: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = utils.load_wav2vec_model(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec84f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing prediction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145c0a6884e3435f865ad7c687f56294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 44s, sys: 36.9 s, total: 6min 21s\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('computing prediction...')\n",
    "dataset = dataset.map(utils.map_to_pred, fn_kwargs={\"model\": model, \"tokenizer\": tokenizer}, writer_batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9caf83",
   "metadata": {},
   "source": [
    "## 3. Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8faa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(utils.os.path.join(utils.predictions_path, 'lr_clean_test_ns_'+ str(int(100 * noise_percentage_factor)) + '%_w2v2_base_960h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e574269",
   "metadata": {},
   "source": [
    "## 4. Compute WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678aeb74-e1a7-4749-a2f9-79303fd4035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer= 92.5 %.\n"
     ]
    }
   ],
   "source": [
    "wer = utils.wer(dataset[\"ground_truth\"], dataset[\"transcription\"])\n",
    "print('wer=', round(100 * wer, 1), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec782a0",
   "metadata": {},
   "source": [
    "## 5. Send all downsampled datasets in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811e1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/dataset_info.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_w2v2_base_960h/state.json [Content-Type=application/json]...\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow [Content-Type=application/octet-stream]...\n",
      "\\ [21/21 files][  4.9 GiB/  4.9 GiB] 100% Done 130.9 MiB/s ETA 00:00:00         \n",
      "Operation completed over 21 objects/4.9 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "#!gsutil -m cp -n -r ./predictions/ gs://capstone_datasets/librispeech/test/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
