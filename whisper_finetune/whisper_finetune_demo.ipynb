{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetuning demo for Whisper\n",
    "codes adapted from Whisper community [here](https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz) and [here](https://huggingface.co/blog/fine-tune-whisper#prepare-environment)\n",
    "\n",
    "Whisper_base finetuned on Chinese only.\n",
    "\n",
    "**Content:**\n",
    "\n",
    "- Preparation\n",
    "    - Prepare environment\n",
    "    - Prepare commonvoice/fleurs dataset\n",
    "    - Prepare Whisper pretrained processor\n",
    "    - Preprocess dataset with Whisper encoder (saved and can be reloaded)\n",
    "    - Prepare evaluation metrics (**Start from here with pre-loaded dataset and whisper processor**)\n",
    "- Finetune\n",
    "    - Load pretrained Whisper for conditional generation\n",
    "    - Train Whisper on prepared dataset\n",
    "\n",
    "\n",
    "[This thread](https://discuss.huggingface.co/t/seq2seqtrainer-enabled-must-be-a-bool-got-nonetype/25680/11) I made on HuggingFace forum may be helpful is any issue happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sivan/asr/whisper_finetune\r\n",
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /opt/conda\r\n",
      "pytorch_env           *  /opt/conda/envs/pytorch_env\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!conda env list\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 23:57:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: must run as root\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
    "!apt update\n",
    "!apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-848rkjj1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-848rkjj1\n",
      "  Resolved https://github.com/huggingface/transformers to commit 504db92e7da010070c36e185332420a1d52c12b2\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (1.23.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (2022.9.13)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (0.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (0.13.1)\n",
      "Requirement already satisfied: filelock in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0.dev0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.25.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (2022.9.24)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: librosa in /home/sivan/.local/lib/python3.9/site-packages (0.9.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (0.56.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.9.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (65.4.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/sivan/.local/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (0.39.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/sivan/.local/lib/python3.9/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sivan/.local/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jiwer in /home/sivan/.local/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: levenshtein==0.20.2 in /home/sivan/.local/lib/python3.9/site-packages (from jiwer) (0.20.2)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /home/sivan/.local/lib/python3.9/site-packages (from levenshtein==0.20.2->jiwer) (2.11.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in /home/sivan/.local/lib/python3.9/site-packages (3.9)\n",
      "Requirement already satisfied: paramiko in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (2.12.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (9.2.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: python-multipart in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: fsspec in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (2022.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: ffmpy in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.6.1)\n",
      "Requirement already satisfied: pandas in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (1.5.1)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (1.23.1)\n",
      "Requirement already satisfied: pycryptodome in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.15.0)\n",
      "Requirement already satisfied: orjson in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: fastapi in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.86.0)\n",
      "Requirement already satisfied: httpx in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.23.0)\n",
      "Requirement already satisfied: uvicorn in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.19.0)\n",
      "Requirement already satisfied: pyyaml in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: websockets in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: pydantic in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (1.10.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from aiohttp->gradio) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: starlette==0.20.4 in /home/sivan/.local/lib/python3.9/site-packages (from fastapi->gradio) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/sivan/.local/lib/python3.9/site-packages (from starlette==0.20.4->fastapi->gradio) (3.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from starlette==0.20.4->fastapi->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from httpx->gradio) (2022.9.24)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in /home/sivan/.local/lib/python3.9/site-packages (from httpx->gradio) (0.15.0)\n",
      "Requirement already satisfied: sniffio in /home/sivan/.local/lib/python3.9/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/sivan/.local/lib/python3.9/site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from jinja2->gradio) (2.1.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/sivan/.local/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
      "Requirement already satisfied: mdit-py-plugins in /home/sivan/.local/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.1)\n",
      "Requirement already satisfied: linkify-it-py~=1.0 in /home/sivan/.local/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib->gradio) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sivan/.local/lib/python3.9/site-packages (from pandas->gradio) (2022.5)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from paramiko->gradio) (37.0.4)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/sivan/.local/lib/python3.9/site-packages (from paramiko->gradio) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from paramiko->gradio) (1.16.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/sivan/.local/lib/python3.9/site-packages (from paramiko->gradio) (4.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->gradio) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->gradio) (3.4)\n",
      "Requirement already satisfied: click>=7.0 in /home/sivan/.local/lib/python3.9/site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
      "Requirement already satisfied: uc-micro-py in /home/sivan/.local/lib/python3.9/site-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/sivan/.huggingface/token\n",
      "\u001B[1m\u001B[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plan A: Load dataset from Common Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downloading zh-CN set took about 20 mins stored in /home/sivan/.cache/huggingface/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/sivan/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/zh-CN/11.0.0/8975395f1d50a6b61f707acd3416761702d3b25412f5fb1004e1db51fe7c304a)\n",
      "Found cached dataset common_voice_11_0 (/home/sivan/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/zh-CN/11.0.0/8975395f1d50a6b61f707acd3416761702d3b25412f5fb1004e1db51fe7c304a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 39637\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 10581\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-CN\", split=\"train+validation\", use_auth_token=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-CN\", split=\"test\", use_auth_token=True)\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'sentence'],\n",
      "        num_rows: 39637\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'sentence'],\n",
      "        num_rows: 10581\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# keep only the audio and transcript\n",
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plan B: try loading fluers instead\n",
    "taking about 2 mins"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fleurs (/home/sivan/.cache/huggingface/datasets/google___fleurs/cmn_hans_cn/2.0.0/aabb39fb29739c495517ac904e2886819b6e344702f0a5b5283cb178b087c94a)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c51cdbd26eb043a59fc94779a12de910"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 3246\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 409\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 945\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "fleurs_ch = load_dataset(\"google/fleurs\", \"cmn_hans_cn\")\n",
    "print(fleurs_ch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1368, 'num_samples': 132480, 'path': '/home/sivan/.cache/huggingface/datasets/downloads/extracted/0453709a21b236bdd65487aa8a2d41cafb9515ca24965f9608ef0983230ce835/cmn_hans_cn/audio/train/5551535928909193992.wav', 'audio': {'path': '5551535928909193992.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00197393,\n",
      "       -0.00212777, -0.00208348]), 'sampling_rate': 16000}, 'transcription': '如 果 他 们 使 用 航 空 的 方 式 运 输 货 物 在 某 些 航 线 上 可 能 要 花 几 天 的 时 间 才 能 卸 货 和 通 关', 'raw_transcription': '如果他们使用航空的方式运输货物，在某些航线上，可能要花几天的时间才能卸货和通关。', 'gender': 1, 'lang_id': 13, 'language': 'Mandarin Chinese', 'lang_group_id': 6}\n"
     ]
    }
   ],
   "source": [
    "print(fleurs_ch[\"train\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'transcription', 'raw_transcription'],\n",
      "        num_rows: 3246\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio', 'transcription', 'raw_transcription'],\n",
      "        num_rows: 409\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'transcription', 'raw_transcription'],\n",
      "        num_rows: 945\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "fleurs_ch = fleurs_ch.remove_columns(['id', 'num_samples', 'path','gender', 'lang_id', 'language', 'lang_group_id'])\n",
    "print(fleurs_ch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Whisper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:59:04.985265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 15:59:05.178473: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-11 15:59:05.720422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-11 15:59:05.720513: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-11 15:59:05.720522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# feature extractor\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Chinese\", task=\"transcribe\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# processor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Chinese\", task=\"transcribe\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from datasets import Audio\n",
    "# resampling from 48kHz to 16kHz\n",
    "# common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': '5551535928909193992.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00197393,\n",
      "       -0.00212777, -0.00208348]), 'sampling_rate': 16000}, 'transcription': '如 果 他 们 使 用 航 空 的 方 式 运 输 货 物 在 某 些 航 线 上 可 能 要 花 几 天 的 时 间 才 能 卸 货 和 通 关', 'raw_transcription': '如果他们使用航空的方式运输货物，在某些航线上，可能要花几天的时间才能卸货和通关。'}\n"
     ]
    }
   ],
   "source": [
    "print(fleurs_ch[\"train\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# batch prepare\n",
    "def prepare_dataset(batch):\n",
    "    # load resampled audio data\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids # make sure to encode the transcription column as ground truth\n",
    "    return batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/812 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0447d52bb2d44fc496a95841788becce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/812 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05b9fa3da0134191ab84a4a6c359a5f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/811 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "527001270dd14be194ec9f513fb354c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/811 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be267d3d3b8449b5a16ad729df975d7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/103 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68871a144b2948578687c1790923e168"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/102 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dde56d1e112f4bdea9051b8ed3cd480c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/102 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74986bbffe6f495188faf3166d6daead"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/102 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddc2f0651db94a969c158f214981271c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/237 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf1370b423264c6a8094c2c837c2fc95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/236 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c83df6c2505a47bdac6e38bf28aa2ba0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/236 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e54f8ce235164e49bd5d0e046614e2ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/236 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a792e8a163e74baa971ab6bbc23e2e28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Will take ~40 mins on 16 processes for common voice (and always crash OOM)\n",
    "# Fleurs takes 3/0.5/1 min for 812/102/237 splits for 4 processes\n",
    "fleurs_ch = fleurs_ch.map(prepare_dataset, remove_columns=fleurs_ch.column_names[\"train\"], num_proc=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 3246\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 409\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 945\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(fleurs_ch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# save processed data to bucket\n",
    "fleurs_ch.save_to_disk('/home/sivan/datasets/fl_ch_features2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/sivan/datasets/fl_ch_features/dataset_dict.json [Content-Type=application/json]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/test/state.json [Content-Type=application/json]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/test/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/test/dataset_info.json [Content-Type=application/json]...\r\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \r\n",
      "significantly faster if you enable parallel composite uploads. This\r\n",
      "feature can be enabled by editing the\r\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\r\n",
      "configuration file. However, note that if you do this large files will\r\n",
      "be uploaded as `composite objects\r\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\r\n",
      "means that any user who downloads such objects will need to have a\r\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\r\n",
      "without a compiled crcmod, computing checksums on composite objects is\r\n",
      "so slow that gsutil disables downloads of composite objects.\r\n",
      "\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/validation/state.json [Content-Type=application/json]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/validation/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/validation/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/train/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/train/state.json [Content-Type=application/json]...\r\n",
      "Copying file:///home/sivan/datasets/fl_ch_features/train/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "- [10/10 files][  4.1 GiB/  4.1 GiB] 100% Done  40.3 MiB/s ETA 00:00:00         \r [7/10 files][ 65.8 MiB/  4.1 GiB]   1% Done                                   /-|/- [7/10 files][582.9 MiB/  4.1 GiB]  13% Done                                   |/-\\ [7/10 files][962.7 MiB/  4.1 GiB]  22% Done                                   // [8/10 files][  1.1 GiB/  4.1 GiB]  26% Done                                   \\|/ [8/10 files][  1.3 GiB/  4.1 GiB]  30% Done 106.2 MiB/s ETA 00:00:27          - [8/10 files][  1.4 GiB/  4.1 GiB]  33% Done  97.9 MiB/s ETA 00:00:29          |/- [8/10 files][  1.5 GiB/  4.1 GiB]  37% Done  84.5 MiB/s ETA 00:00:31          \\ [8/10 files][  1.6 GiB/  4.1 GiB]  39% Done  84.4 MiB/s ETA 00:00:30          /-\\ [8/10 files][  1.8 GiB/  4.1 GiB]  43% Done  85.0 MiB/s ETA 00:00:28          | [8/10 files][  1.9 GiB/  4.1 GiB]  45% Done  85.6 MiB/s ETA 00:00:27          -\\| [8/10 files][  2.0 GiB/  4.1 GiB]  49% Done  85.7 MiB/s ETA 00:00:25          -\\| [9/10 files][  2.1 GiB/  4.1 GiB]  51% Done  65.4 MiB/s ETA 00:00:31          / [9/10 files][  2.2 GiB/  4.1 GiB]  52% Done  56.7 MiB/s ETA 00:00:35          \\|/ [9/10 files][  2.3 GiB/  4.1 GiB]  54% Done  42.8 MiB/s ETA 00:00:44          - [9/10 files][  2.3 GiB/  4.1 GiB]  55% Done  42.8 MiB/s ETA 00:00:43          |/- [9/10 files][  2.4 GiB/  4.1 GiB]  58% Done  42.7 MiB/s ETA 00:00:41          \\ [9/10 files][  2.4 GiB/  4.1 GiB]  59% Done  42.7 MiB/s ETA 00:00:40          /-\\ [9/10 files][  2.5 GiB/  4.1 GiB]  61% Done  42.8 MiB/s ETA 00:00:38          | [9/10 files][  2.6 GiB/  4.1 GiB]  62% Done  42.8 MiB/s ETA 00:00:37          -\\| [9/10 files][  2.6 GiB/  4.1 GiB]  64% Done  42.9 MiB/s ETA 00:00:35          / [9/10 files][  2.7 GiB/  4.1 GiB]  65% Done  42.8 MiB/s ETA 00:00:34          \\|/ [9/10 files][  2.8 GiB/  4.1 GiB]  67% Done  43.1 MiB/s ETA 00:00:32          - [9/10 files][  2.8 GiB/  4.1 GiB]  68% Done  43.1 MiB/s ETA 00:00:31          |/- [9/10 files][  2.9 GiB/  4.1 GiB]  70% Done  43.2 MiB/s ETA 00:00:29          \\ [9/10 files][  2.9 GiB/  4.1 GiB]  71% Done  43.3 MiB/s ETA 00:00:28          /-\\ [9/10 files][  3.0 GiB/  4.1 GiB]  73% Done  43.3 MiB/s ETA 00:00:26          | [9/10 files][  3.1 GiB/  4.1 GiB]  74% Done  43.2 MiB/s ETA 00:00:25          -\\| [9/10 files][  3.2 GiB/  4.1 GiB]  76% Done  42.8 MiB/s ETA 00:00:23          / [9/10 files][  3.2 GiB/  4.1 GiB]  77% Done  42.8 MiB/s ETA 00:00:22          \\|/ [9/10 files][  3.3 GiB/  4.1 GiB]  79% Done  42.8 MiB/s ETA 00:00:20          - [9/10 files][  3.3 GiB/  4.1 GiB]  80% Done  43.2 MiB/s ETA 00:00:19          |/- [9/10 files][  3.4 GiB/  4.1 GiB]  82% Done  43.4 MiB/s ETA 00:00:17          \\ [9/10 files][  3.4 GiB/  4.1 GiB]  83% Done  43.1 MiB/s ETA 00:00:16          /-\\ [9/10 files][  3.5 GiB/  4.1 GiB]  85% Done  42.7 MiB/s ETA 00:00:14          | [9/10 files][  3.6 GiB/  4.1 GiB]  86% Done  42.9 MiB/s ETA 00:00:13          -\\| [9/10 files][  3.6 GiB/  4.1 GiB]  88% Done  42.9 MiB/s ETA 00:00:11          / [9/10 files][  3.7 GiB/  4.1 GiB]  89% Done  43.5 MiB/s ETA 00:00:10          \\|/ [9/10 files][  3.8 GiB/  4.1 GiB]  91% Done  43.3 MiB/s ETA 00:00:08          - [9/10 files][  3.8 GiB/  4.1 GiB]  92% Done  43.0 MiB/s ETA 00:00:07          |/- [9/10 files][  3.9 GiB/  4.1 GiB]  94% Done  43.1 MiB/s ETA 00:00:05          \\ [9/10 files][  4.0 GiB/  4.1 GiB]  96% Done  42.8 MiB/s ETA 00:00:04          /-\\ [9/10 files][  4.0 GiB/  4.1 GiB]  98% Done  43.4 MiB/s ETA 00:00:02          | [9/10 files][  4.1 GiB/  4.1 GiB]  99% Done  43.1 MiB/s ETA 00:00:01          -\r\n",
      "Operation completed over 10 objects/4.1 GiB.                                     \r\n"
     ]
    }
   ],
   "source": [
    "# uploading takes ~30 secs for 4G\n",
    "!gsutil -m cp -n -r /home/sivan/datasets/fl_ch_features gs://capstone_datasets/fleurs/preprocess/fl_ch_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data from disk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 3246\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 409\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 945\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "fleurs_ch = load_from_disk('/home/sivan/datasets/fl_ch_features')\n",
    "print(fleurs_ch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data collator\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sivan/asr/whisper')\n",
    "from utils import custom_normalizer\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions # ids from model.generate\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # normalizer\n",
    "    # pred_str = custom_normalizer(pred_str, \"zh\")\n",
    "    pred_str = [custom_normalizer(str(input_str), \"zh\") for input_str in pred_str]\n",
    "    label_str = [custom_normalizer(str(input_str), \"zh\") for input_str in label_str]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    print(pred_str[:5], label_str[0:5])\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load pretrained Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reduce per_device_train_batch_size if cuda OOM\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/sivan/whisper_base_fl_ch\",\n",
    "    per_device_train_batch_size=16, # originally 16\n",
    "    gradient_accumulation_steps=1,  # originally 1, increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=False, # original True\n",
    "    group_by_length=False, # set true if length is specified in dataset\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False, # set true to push trained model to HF\n",
    "    disable_tqdm=False, # set false to see progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=fleurs_ch[\"train\"],\n",
    "    eval_dataset=fleurs_ch[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose best model on validation set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/sivan/whisper_base_fl_ch/validations\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    per_device_eval_batch_size=32, # 32 for 8000+MiB\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    push_to_hub=False,\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "from transformers import WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Chinese\", task=\"transcribe\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from checkpoint  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 409\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/sivan/whisper_base_fl_ch/checkpoint-2000/config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-base\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": null,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "loading weights file /home/sivan/whisper_base_fl_ch/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['加 南 没 有 大 胜 利 所 以 木 材 非 常 昂 贵 ', '由 于 一 天 只 颁 发 18 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 邻 较 台 ', '公 园 站 第 19 500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 及 与 此 地 应 得 的 尊 严 装 重 和 尊 重 不 要 用 大 屠 杀 混 纳 粹 开 玩 笑 ', '莫 堵 第 一 次 世 界 大 战 中 的 私 女 残 暴 后 各 国 都 可 望 避 免 重 打 负 责 ', '是 为 国 家 安 全 国 问 塔 萨 建 筑 卡 特 徒 利 诸 多 国 际 事 物 例 如 1978 年 接 触 待 维 英 协 议 在 20 世 纪 70 年 来 末 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 之 威 胁 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 r u s t u s a r f o h a n n e s o n ', '还 有 设 会 和 政 治 影 响 例 如 杜 良 单 位 的 使 用 从 钳 次 到 共 和 质 的 转 变 民 族 主 义 相 信 国 家 不 属 于 危 机 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 名 人 的 村 中 漫 步 半 小 时 是 值 得 的 ', '在 宽 国 的 利 益 那 岛 b e r l í b a y 厢 的 建 筑 和 线 的 话 的 构 物 中 心 中 间 散 布 着 传 统 的 红 马 无 定 十 八 世 纪 的 市 场 以 及 古 老 的 清 晨 司 和 教 堂 不 过 这 所 曾 是 比 传 统 的 土 耳 其 更 有 地 重 海 欧 洲 的 氛 围 ', '照 堂 目 的 领 一 先 焚 目 上 方 板 这 有 趣 的 大 理 石 隔 子 雕 所 '] ['迦 南 没 有 大 森 林 所 以 木 材 非 常 昂 贵 ', '由 于 一 天 只 颁 发 十 八 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 领 奖 台 ', '公 园 占 地 19500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 给 予 此 地 应 得 的 尊 严 庄 严 和 尊 重 不 要 用 大 屠 杀 或 纳 粹 开 玩 笑 ', '目 睹 第 一 次 世 界 大 战 中 的 肆 虐 残 暴 后 各 国 都 渴 望 避 免 重 蹈 覆 辙 ', '身 为 国 家 安 全 顾 问 他 曾 协 助 卡 特 处 理 诸 多 国 际 事 务 例 如 1978 年 签 署 戴 维 营 协 议 在 20 世 纪 70 年 代 末 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 质 危 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 许 多 社 会 和 政 治 影 响 例 如 度 量 单 位 的 使 用 从 专 制 到 共 和 制 的 转 变 民 族 主 义 相 信 国 家 不 属 于 唯 一 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 迷 人 的 村 庄 漫 步 半 小 时 是 值 得 的 ', '在 宽 阔 的 林 荫 大 道 玻 璃 外 墙 的 建 筑 和 现 代 化 的 购 物 中 心 之 间 散 布 着 传 统 的 红 瓦 屋 顶 18 世 纪 的 市 场 以 及 古 老 的 清 真 寺 和 教 堂 不 过 这 座 城 市 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '教 堂 墓 地 里 一 些 坟 墓 上 方 摆 着 有 趣 的 大 理 石 鸽 子 雕 塑 ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at /home/sivan/whisper_base_fl_ch/checkpoint-2000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 409\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from checkpoint  2000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/sivan/whisper_base_fl_ch/checkpoint-3000/config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-base\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": null,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "loading weights file /home/sivan/whisper_base_fl_ch/checkpoint-3000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['加 拿 人 没 有 大 胜 利 所 以 牧 材 非 常 昂 贵 ', '由 于 一 天 只 颁 颁 发 十 八 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 邻 较 台 ', '公 园 站 第 19 500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 及 与 此 地 应 得 的 尊 严 装 重 和 尊 重 不 要 用 大 层 沙 或 纳 粹 开 玩 笑 ', '莫 堵 第 一 次 世 界 大 战 中 的 私 女 残 暴 后 各 国 都 可 望 避 免 重 岛 负 责 ', '是 为 国 家 安 全 国 问 塔 克 森 写 住 卡 特 特 处 理 诸 多 国 际 事 物 例 如 1978 年 接 触 带 位 置 写 议 在 20 世 纪 70 年 来 没 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 知 危 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 设 会 和 政 治 影 响 例 如 杜 良 单 位 的 使 用 从 川 次 到 共 和 兹 的 转 变 民 族 主 义 相 信 国 家 不 属 于 危 机 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 名 人 的 村 中 曼 布 半 小 时 是 值 得 的 ', '在 宽 过 的 利 因 那 道 柏 里 外 墙 的 建 筑 和 线 的 话 的 构 物 中 心 中 间 散 布 着 传 统 的 红 马 无 定 18 世 纪 的 市 场 以 及 古 老 的 清 晨 寺 和 教 堂 不 过 这 座 城 是 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '照 堂 目 地 领 一 些 坟 墓 上 方 摆 着 有 趣 的 大 礼 石 格 子 雕 所 '] ['迦 南 没 有 大 森 林 所 以 木 材 非 常 昂 贵 ', '由 于 一 天 只 颁 发 十 八 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 领 奖 台 ', '公 园 占 地 19500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 给 予 此 地 应 得 的 尊 严 庄 严 和 尊 重 不 要 用 大 屠 杀 或 纳 粹 开 玩 笑 ', '目 睹 第 一 次 世 界 大 战 中 的 肆 虐 残 暴 后 各 国 都 渴 望 避 免 重 蹈 覆 辙 ', '身 为 国 家 安 全 顾 问 他 曾 协 助 卡 特 处 理 诸 多 国 际 事 务 例 如 1978 年 签 署 戴 维 营 协 议 在 20 世 纪 70 年 代 末 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 质 危 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 许 多 社 会 和 政 治 影 响 例 如 度 量 单 位 的 使 用 从 专 制 到 共 和 制 的 转 变 民 族 主 义 相 信 国 家 不 属 于 唯 一 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 迷 人 的 村 庄 漫 步 半 小 时 是 值 得 的 ', '在 宽 阔 的 林 荫 大 道 玻 璃 外 墙 的 建 筑 和 现 代 化 的 购 物 中 心 之 间 散 布 着 传 统 的 红 瓦 屋 顶 18 世 纪 的 市 场 以 及 古 老 的 清 真 寺 和 教 堂 不 过 这 座 城 市 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '教 堂 墓 地 里 一 些 坟 墓 上 方 摆 着 有 趣 的 大 理 石 鸽 子 雕 塑 ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at /home/sivan/whisper_base_fl_ch/checkpoint-3000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 409\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from checkpoint  3000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/sivan/whisper_base_fl_ch/checkpoint-4000/config.json\n",
      "Model config WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-base\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": null,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "loading weights file /home/sivan/whisper_base_fl_ch/checkpoint-4000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['加 拿 人 没 有 大 胜 利 所 以 牧 材 非 常 昂 贵 ', '由 于 一 天 只 班 发 18 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 邻 较 台 ', '公 园 站 第 19 500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 及 与 此 地 英 德 的 尊 严 装 重 和 尊 重 不 要 用 大 屠 杀 混 纳 粹 开 玩 笑 ', '莫 堵 第 一 次 世 界 大 战 中 的 私 女 残 暴 后 各 国 都 可 望 避 免 重 岛 负 责 ', '是 美 国 家 安 全 国 问 塔 克 森 写 住 卡 特 t r e n t y 出 多 国 际 事 物 例 如 1978 年 接 触 带 位 置 写 议 在 20 世 纪 70 年 来 没 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 之 危 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 设 会 和 政 治 影 响 例 如 杜 良 单 位 的 使 用 从 川 次 到 共 和 兹 的 转 变 民 族 主 义 相 信 国 家 不 属 于 危 机 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 名 人 的 村 中 曼 布 半 小 时 是 值 得 的 ', '在 宽 过 的 利 因 那 道 柏 里 外 墙 的 建 筑 和 线 的 话 的 构 物 中 心 中 间 散 布 着 传 统 的 红 马 无 定 18 世 纪 的 市 场 以 及 古 老 的 清 晨 司 和 教 堂 不 过 这 座 城 是 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '照 堂 目 的 领 一 先 房 目 上 方 摆 着 有 趣 的 大 礼 石 格 子 雕 所 '] ['迦 南 没 有 大 森 林 所 以 木 材 非 常 昂 贵 ', '由 于 一 天 只 颁 发 十 八 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 领 奖 台 ', '公 园 占 地 19500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 给 予 此 地 应 得 的 尊 严 庄 严 和 尊 重 不 要 用 大 屠 杀 或 纳 粹 开 玩 笑 ', '目 睹 第 一 次 世 界 大 战 中 的 肆 虐 残 暴 后 各 国 都 渴 望 避 免 重 蹈 覆 辙 ', '身 为 国 家 安 全 顾 问 他 曾 协 助 卡 特 处 理 诸 多 国 际 事 务 例 如 1978 年 签 署 戴 维 营 协 议 在 20 世 纪 70 年 代 末 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 质 危 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 许 多 社 会 和 政 治 影 响 例 如 度 量 单 位 的 使 用 从 专 制 到 共 和 制 的 转 变 民 族 主 义 相 信 国 家 不 属 于 唯 一 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 迷 人 的 村 庄 漫 步 半 小 时 是 值 得 的 ', '在 宽 阔 的 林 荫 大 道 玻 璃 外 墙 的 建 筑 和 现 代 化 的 购 物 中 心 之 间 散 布 着 传 统 的 红 瓦 屋 顶 18 世 纪 的 市 场 以 及 古 老 的 清 真 寺 和 教 堂 不 过 这 座 城 市 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '教 堂 墓 地 里 一 些 坟 墓 上 方 摆 着 有 趣 的 大 理 石 鸽 子 雕 塑 ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at /home/sivan/whisper_base_fl_ch/checkpoint-4000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 409\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from checkpoint  4000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['加 拿 人 没 有 大 胜 利 所 以 牧 材 非 常 昂 贵 ', '由 于 一 天 只 班 发 18 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 邻 较 台 ', '公 园 站 第 19 500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 及 与 此 地 英 德 的 尊 严 装 重 和 尊 重 不 要 用 大 屠 杀 混 纳 磺 开 玩 笑 ', '莫 堵 第 一 次 世 界 大 战 中 的 私 女 残 暴 后 各 国 都 可 望 避 免 重 岛 负 责 ', '是 美 国 家 安 全 国 问 塔 克 森 写 住 卡 特 t r e n t y 出 多 国 际 事 物 例 如 1978 年 接 触 带 位 置 写 议 在 20 世 纪 70 年 来 没 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 直 播 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 设 会 和 政 治 影 响 例 如 杜 良 单 位 的 使 用 从 川 次 到 共 和 兹 的 转 变 民 族 主 义 相 信 国 家 不 属 于 危 机 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 名 人 的 村 中 曼 布 半 小 时 是 值 得 的 ', '在 宽 过 的 利 因 那 道 柏 里 外 墙 的 建 筑 和 线 的 话 的 构 物 中 心 中 间 散 布 着 传 统 的 红 马 无 定 18 世 纪 的 市 场 以 及 古 老 的 清 晨 四 和 教 党 不 过 这 所 曾 是 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '照 堂 目 的 领 一 先 房 目 上 方 摆 着 有 趣 的 大 礼 石 格 子 雕 所 '] ['迦 南 没 有 大 森 林 所 以 木 材 非 常 昂 贵 ', '由 于 一 天 只 颁 发 十 八 块 奖 牌 许 多 国 家 的 运 动 员 未 能 登 上 领 奖 台 ', '公 园 占 地 19500 平 方 公 里 分 为 14 个 不 同 的 生 态 区 为 不 同 的 野 生 动 植 物 提 供 支 持 ', '请 给 予 此 地 应 得 的 尊 严 庄 严 和 尊 重 不 要 用 大 屠 杀 或 纳 粹 开 玩 笑 ', '目 睹 第 一 次 世 界 大 战 中 的 肆 虐 残 暴 后 各 国 都 渴 望 避 免 重 蹈 覆 辙 ', '身 为 国 家 安 全 顾 问 他 曾 协 助 卡 特 处 理 诸 多 国 际 事 务 例 如 1978 年 签 署 戴 维 营 协 议 在 20 世 纪 70 年 代 末 实 现 美 中 关 系 正 常 化 1979 年 导 致 伊 朗 人 质 危 机 的 伊 朗 革 命 1979 年 苏 联 入 侵 阿 富 汗 ', '还 有 许 多 社 会 和 政 治 影 响 例 如 度 量 单 位 的 使 用 从 专 制 到 共 和 制 的 转 变 民 族 主 义 相 信 国 家 不 属 于 唯 一 的 统 治 者 而 是 属 于 人 民 ', '在 这 个 迷 人 的 村 庄 漫 步 半 小 时 是 值 得 的 ', '在 宽 阔 的 林 荫 大 道 玻 璃 外 墙 的 建 筑 和 现 代 化 的 购 物 中 心 之 间 散 布 着 传 统 的 红 瓦 屋 顶 18 世 纪 的 市 场 以 及 古 老 的 清 真 寺 和 教 堂 不 过 这 座 城 市 比 传 统 的 土 耳 其 更 有 地 中 海 欧 洲 的 氛 围 ', '教 堂 墓 地 里 一 些 坟 墓 上 方 摆 着 有 趣 的 大 理 石 鸽 子 雕 塑 ']\n",
      "CPU times: user 6min 23s, sys: 58 s, total: 7min 21s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# eval on all checkpoints (~7 mins)\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "import pandas as pd\n",
    "import os\n",
    "results = []\n",
    "for step in [1000,2000,3000,4000]:\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"/home/sivan/whisper_base_fl_ch/checkpoint-{}\".format(step))\n",
    "    print(\"model loaded from checkpoint \", step)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        eval_dataset=fleurs_ch[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=processor.feature_extractor,\n",
    "    )\n",
    "    results.append(trainer.evaluate())\n",
    "\n",
    "# save reuslts\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(os.path.join(os.getcwd(), 'wer_fl_ch.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  eval_loss   eval_wer  eval_runtime  eval_samples_per_second  \\\n",
      "0           0   0.485646  18.331450      102.6121                    3.986   \n",
      "1           1   0.556010  18.451540      101.7179                    4.021   \n",
      "2           2   0.584909  18.762362      102.8929                    3.975   \n",
      "3           3   0.596293  18.783555      102.6578                    3.984   \n",
      "\n",
      "   eval_steps_per_second  \n",
      "0                  0.127  \n",
      "1                  0.128  \n",
      "2                  0.126  \n",
      "3                  0.127  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(os.path.join(os.getcwd(), 'wer_fl_ch.csv'))\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1940 年 8 月 15 日 蒙 军 攻 入 法 国 南 部 这 次 军 官 被 称 为 龙 齐 冰 行 动 ', '该 群 群 岛 位 于 南 极 半 岛 一 倍 120 公 里 处 最 大 的 岛 屿 是 桥 制 国 王 岛 这 里 是 梵 新 村 的 定 居 点 ', '捐 赛 这 些 颜 色 将 根 据 化 学 物 质 的 三 件 性 发 生 变 化 ', '海 地 正 与 民 主 研 究 所 仅 用 的 独 立 研 究 表 明 是 尼 博 尔 的 联 合 国 维 和 部 队 在 不 知 情 的 情 况 下 将 这 种 疾 病 带 到 了 海 地 ', '劳 不 使 全 能 运 动 远 它 会 判 划 虽 然 判 划 能 力 不 是 很 强 游 泳 跳 远 拉 利 能 达 到 人 类 大 力 士 的 无 贝 ', '在 这 份 报 告 的 78 项 建 议 中 第 一 条 建 议 是 在 今 年 年 底 之 前 才 取 心 的 外 交 行 动 目 的 在 于 保 护 伊 拉 克 的 编 辑 免 受 敌 对 势 力 的 迁 害 并 与 英 国 重 建 外 交 关 系 ', '你 可 以 乘 坐 波 达 波 达 出 租 的 摩 托 车 游 览 格 马 短 托 车 乘 的 正 常 当 地 价 格 是 500 国 法 兰 ', '区 域 性 和 继 续 性 的 恶 劣 天 气 现 象 包 括 暴 风 雪 雪 暴 沙 暴 和 沙 城 暴 等 ', '最 终 有 许 多 小 型 的 毛 克 动 包 括 鲨 养 的 虫 毛 以 昆 虫 液 尺 动 物 细 艺 和 鸟 类 等 数 量 多 得 多 的 小 骨 针 列 物 为 事 ', '每 个 人 都 是 社 会 的 一 分 子 都 会 使 用 交 通 系 统 而 几 乎 每 个 人 都 对 交 通 系 统 有 愿 意 演 '] ['1940 年 8 月 15 日 盟 军 攻 入 法 国 南 部 这 次 进 攻 被 称 为 龙 骑 兵 行 动 ', '该 群 岛 位 于 南 极 半 岛 以 北 120 公 里 处 最 大 的 岛 屿 是 乔 治 国 王 岛 这 里 是 繁 星 村 v i l l a l a s e s t r e l l a s 的 定 居 点 ', '卷 心 菜 汁 的 颜 色 将 根 据 化 学 物 质 的 酸 碱 性 发 生 变 化 ', '海 地 正 义 与 民 主 研 究 所 引 用 的 独 立 研 究 表 明 是 尼 泊 尔 的 联 合 国 维 和 部 队 在 不 知 情 的 情 况 下 将 这 种 疾 病 带 到 了 海 地 ', '老 虎 是 全 能 运 动 员 它 会 攀 爬 虽 然 攀 爬 能 力 不 是 很 强 游 泳 跳 远 拉 力 能 达 到 人 类 大 力 士 的 五 倍 ', '在 这 份 报 告 的 78 项 建 议 中 第 一 条 建 议 是 在 今 年 年 底 之 前 采 取 新 的 外 交 行 动 目 的 在 于 保 护 伊 拉 克 的 边 界 免 受 敌 对 势 力 的 侵 害 并 与 邻 国 重 建 外 交 关 系 ', '你 可 以 乘 坐 b o d a b o d a 出 租 的 摩 托 车 游 览 戈 马 g o m a 短 途 车 程 的 正 常 当 地 价 格 是 500 刚 果 法 郎 ', '区 域 性 和 季 节 性 的 恶 劣 天 气 现 象 包 括 暴 风 雪 雪 暴 冰 暴 和 沙 尘 暴 等 ', '最 终 有 许 多 小 型 的 猫 科 动 物 包 括 散 养 的 宠 物 猫 以 昆 虫 啮 齿 动 物 蜥 蜴 和 鸟 类 等 数 量 多 得 多 的 小 型 猎 物 为 食 ', '每 个 人 都 是 社 会 的 一 份 子 都 会 使 用 交 通 系 统 而 几 乎 每 个 人 都 对 交 通 系 统 有 怨 言 ']\n",
      "***** test metrics *****\n",
      "  test_loss               =     0.6577\n",
      "  test_runtime            = 0:03:55.68\n",
      "  test_samples_per_second =       4.01\n",
      "  test_steps_per_second   =      0.127\n",
      "  test_wer                =     19.679\n"
     ]
    }
   ],
   "source": [
    "predict_results  = trainer.predict(fleurs_ch[\"test\"], metric_key_prefix=\"test\")\n",
    "metrics = predict_results.metrics\n",
    "trainer.log_metrics(\"test\", metrics)\n",
    "trainer.save_metrics(\"test\", metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}