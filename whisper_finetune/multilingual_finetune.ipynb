{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetuning demo for Whisper on CommonVoice\n",
    "codes adapted from Whisper community [here](https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz) and [here](https://huggingface.co/blog/fine-tune-whisper#prepare-environment)\n",
    "\n",
    "Whisper_base finetuned on CommonVoice Chinese only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sivan/asr/whisper_finetune\n",
      "# conda environments:\n",
      "#\n",
      "base                     /opt/conda\n",
      "pytorch_env           *  /opt/conda/envs/pytorch_env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 23:57:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: must run as root\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
    "!apt update\n",
    "!apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-848rkjj1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-848rkjj1\n",
      "  Resolved https://github.com/huggingface/transformers to commit 504db92e7da010070c36e185332420a1d52c12b2\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (1.23.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (2022.9.13)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (0.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (0.13.1)\n",
      "Requirement already satisfied: filelock in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sivan/.local/lib/python3.9/site-packages (from transformers==4.25.0.dev0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0.dev0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.25.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers==4.25.0.dev0) (2022.9.24)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: librosa in /home/sivan/.local/lib/python3.9/site-packages (0.9.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (0.56.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.9.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/sivan/.local/lib/python3.9/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (65.4.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/sivan/.local/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (0.39.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/sivan/.local/lib/python3.9/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sivan/.local/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jiwer in /home/sivan/.local/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: levenshtein==0.20.2 in /home/sivan/.local/lib/python3.9/site-packages (from jiwer) (0.20.2)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /home/sivan/.local/lib/python3.9/site-packages (from levenshtein==0.20.2->jiwer) (2.11.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in /home/sivan/.local/lib/python3.9/site-packages (3.9)\n",
      "Requirement already satisfied: paramiko in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (2.12.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (9.2.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: python-multipart in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: fsspec in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (2022.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: ffmpy in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.6.1)\n",
      "Requirement already satisfied: pandas in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (1.5.1)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (1.23.1)\n",
      "Requirement already satisfied: pycryptodome in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.15.0)\n",
      "Requirement already satisfied: orjson in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: fastapi in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.86.0)\n",
      "Requirement already satisfied: httpx in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.23.0)\n",
      "Requirement already satisfied: uvicorn in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.19.0)\n",
      "Requirement already satisfied: pyyaml in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: websockets in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: pydantic in /home/sivan/.local/lib/python3.9/site-packages (from gradio) (1.10.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from aiohttp->gradio) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/sivan/.local/lib/python3.9/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: starlette==0.20.4 in /home/sivan/.local/lib/python3.9/site-packages (from fastapi->gradio) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/sivan/.local/lib/python3.9/site-packages (from starlette==0.20.4->fastapi->gradio) (3.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from starlette==0.20.4->fastapi->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from httpx->gradio) (2022.9.24)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in /home/sivan/.local/lib/python3.9/site-packages (from httpx->gradio) (0.15.0)\n",
      "Requirement already satisfied: sniffio in /home/sivan/.local/lib/python3.9/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/sivan/.local/lib/python3.9/site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from jinja2->gradio) (2.1.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/sivan/.local/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
      "Requirement already satisfied: mdit-py-plugins in /home/sivan/.local/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.1)\n",
      "Requirement already satisfied: linkify-it-py~=1.0 in /home/sivan/.local/lib/python3.9/site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib->gradio) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sivan/.local/lib/python3.9/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sivan/.local/lib/python3.9/site-packages (from pandas->gradio) (2022.5)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from paramiko->gradio) (37.0.4)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/sivan/.local/lib/python3.9/site-packages (from paramiko->gradio) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from paramiko->gradio) (1.16.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/sivan/.local/lib/python3.9/site-packages (from paramiko->gradio) (4.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->gradio) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->gradio) (3.4)\n",
      "Requirement already satisfied: click>=7.0 in /home/sivan/.local/lib/python3.9/site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
      "Requirement already satisfied: uc-micro-py in /home/sivan/.local/lib/python3.9/site-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/sivan/.huggingface/token\n",
      "\u001B[1m\u001B[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dataset from Common Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downloading zh-CN set took about 20 mins stored in /home/sivan/.cache/huggingface/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/sivan/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/zh-CN/11.0.0/8975395f1d50a6b61f707acd3416761702d3b25412f5fb1004e1db51fe7c304a)\n",
      "Found cached dataset common_voice_11_0 (/home/sivan/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/zh-CN/11.0.0/8975395f1d50a6b61f707acd3416761702d3b25412f5fb1004e1db51fe7c304a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 39637\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 10581\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-CN\", split=\"train+validation\", use_auth_token=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-CN\", split=\"test\", use_auth_token=True)\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'sentence'],\n",
      "        num_rows: 39637\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'sentence'],\n",
      "        num_rows: 10581\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# keep only the audio and transcript\n",
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 02:05:36.425830: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 02:05:37.859781: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-07 02:05:39.754429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-07 02:05:39.754585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-07 02:05:39.754597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8391fa372804141b5a3a7a987a6eec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature extractor\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Chinese\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# processor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Chinese\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare Data\n",
    "Change sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': '/home/sivan/.cache/huggingface/datasets/downloads/extracted/a431e9b847c1f8a129320d049fd36b92f5f9b5f5cc3afb46b78b1203b26a4d25/cv-corpus-11.0-2022-09-21/zh-CN/clips/common_voice_zh-CN_18531536.mp3', 'array': array([0.        , 0.        , 0.        , ..., 0.00105894, 0.00092286,\n",
      "       0.00065482], dtype=float32), 'sampling_rate': 48000}, 'sentence': '汉元鼎六年，武帝平定南越国，南越之地重新划郡，番禺仍为南海郡治。'}\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': '/home/sivan/.cache/huggingface/datasets/downloads/extracted/a431e9b847c1f8a129320d049fd36b92f5f9b5f5cc3afb46b78b1203b26a4d25/cv-corpus-11.0-2022-09-21/zh-CN/clips/common_voice_zh-CN_18531536.mp3', 'array': array([0.        , 0.        , 0.        , ..., 0.00127417, 0.00100847,\n",
      "       0.00099752], dtype=float32), 'sampling_rate': 16000}, 'sentence': '汉元鼎六年，武帝平定南越国，南越之地重新划郡，番禺仍为南海郡治。'}\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# batch prepare\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5fe6d9edfc496ba2f85f65c6d4c085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/4955 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b580760317a45168bbfb448e37d4d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/4955 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ee21cff764437c8e8d18d1e081dbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/4955 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b77c85a255442b95d68fc1b9584694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/4955 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe8a4c5575d46cbbbaa79e95023e0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/4955 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ceb82dbd5074bdc84b7da956636ea4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/4954 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84ad6c81d764c14a8facda17a01f200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/4954 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e118e4ed2b42f28a35374b306ecf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/4954 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data collector\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load pretrained Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-hi\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}