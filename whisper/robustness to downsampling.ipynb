{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing Whisper's Robustness to Downsampled Librispeech\n",
    "\n",
    "using Hugging Face version [Whisper model](https://huggingface.co/docs/transformers/model_doc/whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import utils\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 available cpus\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method, cpu_count\n",
    "set_start_method(\"spawn\")\n",
    "num_cpus = cpu_count()\n",
    "print('{} available cpus'.format(num_cpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set paths for input/output\n",
    "datasets_path = os.path.join('/home/sivan/datasets')\n",
    "predictions_path = os.path.join('/home/sivan/predictions')\n",
    "# create folders if they do not already exist\n",
    "if not os.path.exists(datasets_path): os.makedirs(datasets_path)\n",
    "if not os.path.exists(predictions_path): os.makedirs(predictions_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting 1000~16000Hz downsampled data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing item: file://./lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_500Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_0%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_0%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_0%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_1%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_1%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_1%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_2%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_2%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_2%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_3%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_3%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_3%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_4%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_4%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_4%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_5%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_5%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_5%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_6%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_6%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_6%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_w2v2_base_960h/state.json\r\n"
     ]
    }
   ],
   "source": [
    "# Loading data from bucket https://console.cloud.google.com/storage/browser/capstone_datasets/librispeech/test/predictions;tab=objects?project=ecbm4040-an3078-326401&pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false\n",
    "# downsampled data saved by wav2vec-downsample branch https://github.com/anhvung/Capstone-Audio-Transcription/blob/wav2vec-downsample/wav2vec/downsample.ipynb\n",
    "# 9.4GB in total taking ~60s\n",
    "!gsutil -m cp -n -r gs://capstone_datasets/librispeech/test/predictions/* ."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Whisper Exploration-noisysub.ipynb'\t   lr_clean_test_ns_1%_w2v2_base_960h\r\n",
      "'Whisper Exploration.ipynb'\t\t   lr_clean_test_ns_2%_w2v2_base_960h\r\n",
      " __pycache__\t\t\t\t   lr_clean_test_ns_3%_w2v2_base_960h\r\n",
      " audio.mp3\t\t\t\t   lr_clean_test_ns_4%_w2v2_base_960h\r\n",
      " datasets\t\t\t\t   lr_clean_test_ns_5%_w2v2_base_960h\r\n",
      " lr_clean_test_ds_1000Hz_w2v2_base_960h    lr_clean_test_ns_6%_w2v2_base_960h\r\n",
      " lr_clean_test_ds_16000Hz_w2v2_base_960h   lr_clean_test_w2v2_base_960h\r\n",
      " lr_clean_test_ds_2000Hz_w2v2_base_960h    predictions\r\n",
      " lr_clean_test_ds_4000Hz_w2v2_base_960h    requirements.txt\r\n",
      " lr_clean_test_ds_500Hz_w2v2_base_960h\t  'robustness on downsampling.ipynb'\r\n",
      " lr_clean_test_ds_8000Hz_w2v2_base_960h    utils.py\r\n",
      " lr_clean_test_ns_0%_w2v2_base_960h\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6 types of sample rates\n",
    "sr = [500, 1000, 2000, 4000, 8000, 16000]\n",
    "datasets = {}\n",
    "\n",
    "# load datasets and remove results\n",
    "for i in sr:\n",
    "    datasets[i] = utils.load_from_disk(utils.os.path.join(datasets_path, 'lr_clean_test_ds_{}Hz_w2v2_base_960h'.format(i)))\n",
    "    datasets[i].remove_columns(['logits', 'transcription', 'label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['audio', 'label', 'ground_truth', 'logits', 'transcription'],\n    num_rows: 2620\n})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[500]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing on Whisper-base.enb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\r\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-0c6zn4_b\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-0c6zn4_b\r\n",
      "  Resolved https://github.com/openai/whisper.git to commit 9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (1.19.5)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (1.10.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (4.62.3)\r\n",
      "Collecting more-itertools\r\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.8/52.8 KB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: transformers>=4.19.0 in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (4.22.2)\r\n",
      "Collecting ffmpeg-python==0.2.0\r\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\r\n",
      "Collecting future\r\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m829.2/829.2 KB\u001B[0m \u001B[31m18.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (0.10.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.9.13)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (2.27.1)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (4.11.1)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->whisper==1.0) (4.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.7)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.7.0)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\r\n",
      "Building wheels for collected packages: whisper, future\r\n",
      "  Building wheel for whisper (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175217 sha256=41fdce1e33a6d8095791205e58f8417cff44393133556250b31e4208524dc9f7\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qxcdlpv0/wheels/16/15/89/1c7bb31bd0006793a95549d04785121a8a36daad9158e1e43a\r\n",
      "  Building wheel for future (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=63a7e15feba4d28d2d550290a1761dac0fb450e1a88fd699a835525828f018c9\r\n",
      "  Stored in directory: /home/sivan/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\r\n",
      "Successfully built whisper future\r\n",
      "Installing collected packages: more-itertools, future, ffmpeg-python, whisper\r\n",
      "Successfully installed ffmpeg-python-0.2.0 future-0.18.2 more-itertools-9.0.0 whisper-1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 71,825,408 parameters.\n"
     ]
    }
   ],
   "source": [
    "# load base model and review\n",
    "model = whisper.load_model(\"base.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/185k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b1f18ff434847efb92868afa838892b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/844 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3227885820b4727956819c0ef2912c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/999k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69353f8bd5cd467b9113a88905ee245b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef74f6dc0729413dbcd0979289e144e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba06f5b1cbdc4a27b8debdffaab4ebd9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.08k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b741559d4104fc782bcaaf8f55d3373"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.72k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70bf0dc32a9347868fa854cd2030d1a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfcfd27506ed49288578ea7f9d6a8112"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/151M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "924995ed0fee4fd8951236f9914e917d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load base model and processor\n",
    "processor, model = utils.load_whisper(\"openai/whisper-base.en\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/185k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71b889982e4f4b88aa6b7562bc2604ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/844 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b72247cb20045c1a23c7765291923f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/999k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a136c23266e4c18bd8c72ed10cda7a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6cc5b5af69445cd90173774040e7492"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "290913f4ad3349fdbd1448a638ffa743"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.08k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1797f1720fb54539a24cc49693827035"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.72k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9a5f339cae34f4a86786f5d3b86467b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f60a172b9df4b86ae1b26baf8c3da7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00e7b320eb08414c81fa62edf69f7fb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# load base model and processor\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m processor, model \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_whisper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mopenai/whisper-base.en\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m results \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      5\u001B[0m results[\u001B[38;5;241m500\u001B[39m] \u001B[38;5;241m=\u001B[39m datasets[\u001B[38;5;241m500\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(utils\u001B[38;5;241m.\u001B[39mmap_to_pred,\n\u001B[1;32m      6\u001B[0m                                  fn_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocessor\u001B[39m\u001B[38;5;124m\"\u001B[39m: processor},\n\u001B[1;32m      7\u001B[0m                                  batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, remove_columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspeech\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/Desktop/capstone/Capstone-Audio-Transcription/whisper/utils.py:55\u001B[0m, in \u001B[0;36mload_whisper\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;124;03mload and return wav2vec tokenizer and model from huggingface\u001B[39;00m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     54\u001B[0m processor \u001B[38;5;241m=\u001B[39m WhisperProcessor\u001B[38;5;241m.\u001B[39mfrom_pretrained(path)\n\u001B[0;32m---> 55\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mWhisperForConditionalGeneration\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m processor, model\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/transformers/modeling_utils.py:2089\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   2074\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2075\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m   2076\u001B[0m     cached_file_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m   2077\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m   2078\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2087\u001B[0m         _commit_hash\u001B[38;5;241m=\u001B[39mcommit_hash,\n\u001B[1;32m   2088\u001B[0m     )\n\u001B[0;32m-> 2089\u001B[0m     resolved_archive_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcached_file_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2091\u001B[0m     \u001B[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001B[39;00m\n\u001B[1;32m   2092\u001B[0m     \u001B[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001B[39;00m\n\u001B[1;32m   2093\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename \u001B[38;5;241m==\u001B[39m SAFE_WEIGHTS_NAME:\n\u001B[1;32m   2094\u001B[0m         \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/transformers/utils/hub.py:409\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    406\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 409\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    425\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    426\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    427\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    428\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    429\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/huggingface_hub/file_download.py:1226\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001B[0m\n\u001B[1;32m   1223\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m temp_file_manager() \u001B[38;5;28;01mas\u001B[39;00m temp_file:\n\u001B[1;32m   1224\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloading \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, temp_file\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m-> 1226\u001B[0m     \u001B[43mhttp_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1232\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1234\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstoring \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m in cache at \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, blob_path)\n\u001B[1;32m   1235\u001B[0m os\u001B[38;5;241m.\u001B[39mreplace(temp_file\u001B[38;5;241m.\u001B[39mname, blob_path)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/huggingface_hub/file_download.py:490\u001B[0m, in \u001B[0;36mhttp_get\u001B[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001B[0m\n\u001B[1;32m    481\u001B[0m total \u001B[38;5;241m=\u001B[39m resume_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(content_length) \u001B[38;5;28;01mif\u001B[39;00m content_length \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    482\u001B[0m progress \u001B[38;5;241m=\u001B[39m tqdm(\n\u001B[1;32m    483\u001B[0m     unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    484\u001B[0m     unit_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    488\u001B[0m     disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m(logger\u001B[38;5;241m.\u001B[39mgetEffectiveLevel() \u001B[38;5;241m==\u001B[39m logging\u001B[38;5;241m.\u001B[39mNOTSET),\n\u001B[1;32m    489\u001B[0m )\n\u001B[0;32m--> 490\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_content(chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m):\n\u001B[1;32m    491\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chunk:  \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[1;32m    492\u001B[0m         progress\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(chunk))\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/urllib3/response.py:627\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp):\n\u001B[0;32m--> 627\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    630\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/urllib3/response.py:566\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    563\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    565\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 566\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    567\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    568\u001B[0m         flush_decoder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/site-packages/urllib3/response.py:532\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    531\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/http/client.py:462\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    461\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 462\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/http/client.py:506\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    501\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[1;32m    503\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 506\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1239\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1240\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/asr/lib/python3.9/ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# compute prediction for all datasets\n",
    "\n",
    "results = {}\n",
    "for i in sr:\n",
    "    results[i] = datasets[i].map(utils.map_to_pred,\n",
    "                                 num_proc=num_cpus,\n",
    "                                 fn_kwargs={\"model\": model, \"processor\": processor},\n",
    "                                 batched=True, batch_size=16)\n",
    "    results.save_to_disk(utils.os.path.join(predictions_path, 'lr_clean_test_ds_' + str(i) + 'Hz_whisper_base.en'))\n",
    "\n",
    "!gsutil -m cp -n -r ./predictions/ gs://capstone_datasets/librispeech/test/whisper_downsample/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WER (reference, hypothesis_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}