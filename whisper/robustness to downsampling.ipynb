{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing Whisper's Robustness to Downsampled Librispeech\n",
    "\n",
    "using Hugging Face version [Whisper model](https://huggingface.co/docs/transformers/model_doc/whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import utils\n",
    "import transformers\n",
    "import os\n",
    "transformers.logging.set_verbosity_error()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 available cpus\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method, cpu_count\n",
    "set_start_method(\"spawn\")\n",
    "num_cpus = cpu_count()\n",
    "print('{} available cpus'.format(num_cpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# set paths for input/output\n",
    "root = '/home/sivan'\n",
    "project = '/home/sivan/asr'\n",
    "datasets_path = os.path.join(root, 'datasets')\n",
    "predictions_path = os.path.join(root, 'predictions')\n",
    "# create folders if they do not already exist\n",
    "if not os.path.exists(datasets_path): os.makedirs(datasets_path)\n",
    "if not os.path.exists(predictions_path): os.makedirs(predictions_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting 1000~16000Hz downsampled data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing item: file://./lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_1000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_1000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_16000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_2000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_16000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_2000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_4000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_500Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_4000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_500Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_500Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_8000Hz_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_0%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ds_8000Hz_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_0%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_1%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_1%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_0%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_1%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_2%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_2%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_2%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_3%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_3%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_3%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_4%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_4%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_4%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_5%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_5%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_5%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_6%_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_6%_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_w2v2_base_960h/dataset_info.json\r\n",
      "Skipping existing item: file://./lr_clean_test_w2v2_base_960h/dataset.arrow\r\n",
      "Skipping existing item: file://./lr_clean_test_ns_6%_w2v2_base_960h/state.json\r\n",
      "Skipping existing item: file://./lr_clean_test_w2v2_base_960h/state.json\r\n"
     ]
    }
   ],
   "source": [
    "# Loading data from bucket https://console.cloud.google.com/storage/browser/capstone_datasets/librispeech/test/predictions;tab=objects?project=ecbm4040-an3078-326401&pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false\n",
    "# downsampled data saved by wav2vec-downsample branch https://github.com/anhvung/Capstone-Audio-Transcription/blob/wav2vec-downsample/wav2vec/downsample.ipynb\n",
    "# 9.4GB in total taking ~60s\n",
    "os.chdir(datasets_path)\n",
    "!gsutil -m cp -n -r gs://capstone_datasets/librispeech/test/predictions/* .\n",
    "os.chdir(project)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 6 types of sample rates\n",
    "sr = [500, 1000, 2000, 4000, 8000, 16000]\n",
    "datasets = {}\n",
    "\n",
    "# load datasets and remove results\n",
    "for i in sr:\n",
    "    datasets[i] = utils.load_from_disk(utils.os.path.join(datasets_path, 'lr_clean_test_ds_{}Hz_w2v2_base_960h'.format(i)))\n",
    "    datasets[i] = datasets[i].remove_columns(['logits', 'transcription', 'label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'ground_truth'],\n",
      "    num_rows: 2620\n",
      "})\n",
      "{'audio': {'path': None, 'array': array([-1.52587891e-04, -1.83105469e-04, -2.13623047e-04, ...,\n",
      "        3.05175781e-05,  0.00000000e+00,  0.00000000e+00]), 'sampling_rate': 500}, 'ground_truth': 'WELL NOW ENNIS I DECLARE YOU HAVE A HEAD AND SO HAS MY STICK'}\n"
     ]
    }
   ],
   "source": [
    "# inspecting metadata\n",
    "print(datasets[500])\n",
    "print(datasets[500][10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing on Whisper-base.enb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting git+https://github.com/openai/whisper.git\r\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-6eoiq963\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-6eoiq963\r\n",
      "  Resolved https://github.com/openai/whisper.git to commit 9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from whisper==1.0) (1.23.1)\r\n",
      "Requirement already satisfied: torch in /home/sivan/.local/lib/python3.9/site-packages (from whisper==1.0) (1.10.0)\r\n",
      "Requirement already satisfied: tqdm in /home/sivan/.local/lib/python3.9/site-packages (from whisper==1.0) (4.64.1)\r\n",
      "Requirement already satisfied: more-itertools in /home/sivan/.local/lib/python3.9/site-packages (from whisper==1.0) (9.0.0)\r\n",
      "Requirement already satisfied: transformers>=4.19.0 in /home/sivan/.local/lib/python3.9/site-packages (from whisper==1.0) (4.23.1)\r\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /home/sivan/.local/lib/python3.9/site-packages (from whisper==1.0) (0.2.0)\r\n",
      "Requirement already satisfied: future in /home/sivan/.local/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\r\n",
      "Requirement already satisfied: filelock in /home/sivan/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/sivan/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.13.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sivan/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sivan/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.9.13)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/sivan/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.10.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from torch->whisper==1.0) (4.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.11)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 71,825,408 parameters.\n"
     ]
    }
   ],
   "source": [
    "# load base model and review\n",
    "model = whisper.load_model(\"base.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# load base model and processor\n",
    "processor, model = utils.load_whisper(\"openai/whisper-base.en\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start eval on 500 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10f87a79adfe493a9961a8e5b378dd3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 08:36:30.579037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 08:36:30.801291: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 08:36:31.630669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-10-22 08:36:31.630810: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-10-22 08:36:31.630822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/sivan/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1296: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Start eval on 1000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "925d4058af364a6cbca4c12b1649d4eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Start eval on 2000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b07c4f0c9b64daca5f8dbf3936e5eb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Start eval on 4000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f18a8a6cc5640f68a7ef7d44bacdb64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Start eval on 8000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d11f70316c62443285f670ff30f9fa62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "Start eval on 16000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "687bf0f383f14e5b96844f76307bba59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "CPU times: user 2h 17min 32s, sys: 5min 24s, total: 2h 22min 56s\n",
      "Wall time: 1h 39min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute prediction for all datasets\n",
    "results = {}\n",
    "for i in sr:\n",
    "    print(\"Start eval on\", i, \"Hz\")\n",
    "    # eval on batches\n",
    "    results[i] = datasets[i].map(utils.map_to_pred,\n",
    "                                 fn_kwargs={\"model\": model, \"processor\": processor},\n",
    "                                 # num_proc=num_cpus,\n",
    "                                 writer_batch_size=1000)\n",
    "    # save results to output folder\n",
    "    print(\"Saving dataset...\")\n",
    "    results[i].save_to_disk(utils.os.path.join(predictions_path, 'lr_clean_test_ds_' + str(i) + 'Hz_whisper_base.en'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_whisper_base.en/cache-bbe35ccd0cabbbe8.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/state.json [Content-Type=application/json]...\r\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \r\n",
      "significantly faster if you enable parallel composite uploads. This\r\n",
      "feature can be enabled by editing the\r\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\r\n",
      "configuration file. However, note that if you do this large files will\r\n",
      "be uploaded as `composite objects\r\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\r\n",
      "means that any user who downloads such objects will need to have a\r\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\r\n",
      "without a compiled crcmod, computing checksums on composite objects is\r\n",
      "so slow that gsutil disables downloads of composite objects.\r\n",
      "\r\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_whisper_base.en/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/cache-a182a002cc3a9425.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_whisper_base.en/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/cache-10039e94e327bedf.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_whisper_base.en/state.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_whisper_base.en/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/cache-84fe5b479d8af6b6.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_whisper_base.en/cache-3abe8a8998414327.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/state.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/cache-ec8f89541ee5ba9e.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_4000Hz_whisper_base.en/cache-db074d86e2607584.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_whisper_base.en/state.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_whisper_base.en/cache-909da0a32abad0d7.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_1000Hz_whisper_base.en/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/cache-16aada9f5c109671.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_16000Hz_whisper_base.en/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/cache-a14f30576fb97091.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/cache-ee3fa9e711345eae.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/cache-ddae5cf0d31915ae.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_500Hz_whisper_base.en/cache-5127d726e9b2d2b1.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_whisper_base.en/state.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_whisper_base.en/dataset_info.json [Content-Type=application/json]...\r\n",
      "-\r[8/35 files][ 86.3 MiB/ 13.4 GiB]   0% Done                                   Copying file://./predictions/lr_clean_test_ds_2000Hz_whisper_base.en/cache-3cabaa3f8e695c90.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_whisper_base.en/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_2000Hz_whisper_base.en/cache-33adad6519062434.arrow [Content-Type=application/octet-stream]...\r\n",
      "-\r[10/35 files][  6.4 GiB/ 13.4 GiB]  47% Done 350.1 MiB/s ETA 00:00:20         \r [10/35 files][929.4 MiB/ 13.4 GiB]   6% Done                                  \\|/ [10/35 files][  1.6 GiB/ 13.4 GiB]  11% Done                                  - [10/35 files][  1.9 GiB/ 13.4 GiB]  14% Done                                  |/- [10/35 files][  2.6 GiB/ 13.4 GiB]  19% Done                                  \\ [10/35 files][  3.0 GiB/ 13.4 GiB]  22% Done                                  /-\\ [10/35 files][  3.6 GiB/ 13.4 GiB]  27% Done                                  | [10/35 files][  4.0 GiB/ 13.4 GiB]  29% Done 348.0 MiB/s ETA 00:00:28         -\\| [10/35 files][  4.7 GiB/ 13.4 GiB]  35% Done 352.5 MiB/s ETA 00:00:25         / [10/35 files][  5.0 GiB/ 13.4 GiB]  37% Done 353.2 MiB/s ETA 00:00:24         \\|/ [10/35 files][  5.7 GiB/ 13.4 GiB]  42% Done 353.2 MiB/s ETA 00:00:22         - [10/35 files][  6.0 GiB/ 13.4 GiB]  45% Done 351.2 MiB/s ETA 00:00:21         |/Copying file://./predictions/lr_clean_test_ds_8000Hz_whisper_base.en/cache-85d53baaa9d13c05.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_whisper_base.en/dataset_info.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_whisper_base.en/state.json [Content-Type=application/json]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_whisper_base.en/cache-581d5d53a5118524.arrow [Content-Type=application/octet-stream]...\r\n",
      "Copying file://./predictions/lr_clean_test_ds_8000Hz_whisper_base.en/dataset.arrow [Content-Type=application/octet-stream]...\r\n",
      "-\r[34/35 files][ 13.4 GiB/ 13.4 GiB]  99% Done 102.4 MiB/s ETA 00:00:00         \r [10/35 files][  8.1 GiB/ 13.4 GiB]  60% Done 352.0 MiB/s ETA 00:00:15         -\\| [10/35 files][  8.8 GiB/ 13.4 GiB]  65% Done 354.1 MiB/s ETA 00:00:13         / [10/35 files][  9.2 GiB/ 13.4 GiB]  68% Done 352.5 MiB/s ETA 00:00:12         \\|/ [10/35 files][  9.8 GiB/ 13.4 GiB]  73% Done 350.0 MiB/s ETA 00:00:10         - [10/35 files][ 10.2 GiB/ 13.4 GiB]  75% Done 346.0 MiB/s ETA 00:00:10         |/- [10/35 files][ 10.7 GiB/ 13.4 GiB]  80% Done 321.8 MiB/s ETA 00:00:08         \\ [11/35 files][ 10.9 GiB/ 13.4 GiB]  81% Done 288.8 MiB/s ETA 00:00:09         | [13/35 files][ 10.9 GiB/ 13.4 GiB]  81% Done 277.2 MiB/s ETA 00:00:09         // [15/35 files][ 11.0 GiB/ 13.4 GiB]  82% Done 255.6 MiB/s ETA 00:00:09         -\\\\ [19/35 files][ 11.4 GiB/ 13.4 GiB]  84% Done 237.1 MiB/s ETA 00:00:09         | [20/35 files][ 11.5 GiB/ 13.4 GiB]  86% Done 233.9 MiB/s ETA 00:00:08         | [24/35 files][ 11.6 GiB/ 13.4 GiB]  86% Done 231.3 MiB/s ETA 00:00:08         / [25/35 files][ 11.7 GiB/ 13.4 GiB]  87% Done 228.7 MiB/s ETA 00:00:08         -- [28/35 files][ 11.9 GiB/ 13.4 GiB]  88% Done 240.7 MiB/s ETA 00:00:06         \\|-|/\\/-\\ [32/35 files][ 13.1 GiB/ 13.4 GiB]  97% Done 156.2 MiB/s ETA 00:00:02         | [32/35 files][ 13.2 GiB/ 13.4 GiB]  98% Done 150.8 MiB/s ETA 00:00:01         / [33/35 files][ 13.2 GiB/ 13.4 GiB]  98% Done 145.5 MiB/s ETA 00:00:01         \\|/ [35/35 files][ 13.4 GiB/ 13.4 GiB] 100% Done  81.9 MiB/s ETA 00:00:00         \r\n",
      "Operation completed over 35 objects/13.4 GiB.                                    \r\n"
     ]
    }
   ],
   "source": [
    "# upload results to bucket ~20s for 13.5G\n",
    "os.chdir(root)\n",
    "!gsutil -m cp -n -r ./predictions/ gs://capstone_datasets/librispeech/test/whisper_downsample/\n",
    "os.chdir(project)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Helper for prediction data before WER\n",
    "# Remove it after modification on datasets\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "normalizer = EnglishTextNormalizer()\n",
    "\n",
    "def map_trans(batch):\n",
    "    transcription = batch['transcription'][0]\n",
    "    transcription = normalizer(batch['transcription'])\n",
    "    batch['transcription'] = transcription\n",
    "    return batch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7840b70becc0477fb9655e385f39d758"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: Whisper_base.en, ls-test-clean-500Hz: 99.4 %.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3836a22da2814448882cddb92cc8f9e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: Whisper_base.en, ls-test-clean-1000Hz: 305.2 %.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36f1eaef81964e37bbf3897ec37cfaf1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: Whisper_base.en, ls-test-clean-2000Hz: 60.9 %.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "526b06e30f3a41df91cd9a2fca84bc38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: Whisper_base.en, ls-test-clean-4000Hz: 13.2 %.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70aeea58bdb7425fac4cd7e9df48920c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: Whisper_base.en, ls-test-clean-8000Hz: 4.8 %.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2620 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fe8d10dff1c4245ad47fa16a2c3f058"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: Whisper_base.en, ls-test-clean-16000Hz: 4.3 %.\n"
     ]
    }
   ],
   "source": [
    "# load prediction datasets and calculate WER\n",
    "\n",
    "# 6 types of sample rates\n",
    "sr = [500, 1000, 2000, 4000, 8000, 16000]\n",
    "predictions = {}\n",
    "\n",
    "# WER (reference, hypothesis_clean)\n",
    "for i in sr:\n",
    "    predictions[i] = utils.load_from_disk(utils.os.path.join(predictions_path, 'lr_clean_test_ds_{}Hz_whisper_base.en'.format(i)))\n",
    "    predictions[i] = predictions[i].map(map_trans)\n",
    "    predictions[i].save_to_disk(utils.os.path.join(predictions_path, 'lr_clean_test_ds_' + str(i) + 'Hz_whisper_base.en'))\n",
    "    print('WER: Whisper_base.en, ls-test-clean-{}Hz:'.format(i), utils.format_wer(predictions[i][\"ground_truth\"], predictions[i][\"transcription\"]), '%.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}