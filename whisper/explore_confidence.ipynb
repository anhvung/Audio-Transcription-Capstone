{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore confidence scores with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonin/Documents/Projects/capstone/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from confidence_utils import *\n",
    "\n",
    "from datasets import load_dataset\n",
    "from IPython.display import HTML as html_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fleurs (/Users/antonin/.cache/huggingface/datasets/google___fleurs/en_us/2.0.0/aabb39fb29739c495517ac904e2886819b6e344702f0a5b5283cb178b087c94a)\n",
      "100%|██████████| 3/3 [00:00<00:00, 90.94it/s]\n"
     ]
    }
   ],
   "source": [
    "fleurs_en = load_dataset(\"google/fleurs\", \"en_us\")\n",
    "fleurs_en = fleurs_en.remove_columns(['id', 'num_samples', 'path', 'gender', 'lang_id', 'language', 'lang_group_id'])\n",
    "fleurs_en = fleurs_en['train'].select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_en, model_en = load_whisper_with_confidence_scores('openai/whisper-base', 'English')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/antonin/.cache/huggingface/datasets/google___fleurs/en_us/2.0.0/aabb39fb29739c495517ac904e2886819b6e344702f0a5b5283cb178b087c94a/cache-0ae6043dece4a134.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['transcription', 'raw_transcription', 'string_pred', 'tokens_pred', 'probs_tokens_pred', 'ground_truth', 'wer'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.config.forced_decoder_ids = processor_en.get_decoder_prompt_ids(language = \"en\", task = \"transcribe\")\n",
    "fleurs_en = fleurs_en.map(map_to_pred_and_confidence_scores, \n",
    "    fn_kwargs={\"processor\": processor_en, \"model\": model_en, \"lang\": \"en\"}, \n",
    "    batched=True, \\\n",
    "    remove_columns=['audio'], \n",
    "    batch_size = 1)\n",
    "fleurs_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save processed data with confidence indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleurs_en.save_to_disk(os.path.join(predictions_confidence_path, 'fleurs_en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load processed data with confidence indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['transcription', 'raw_transcription', 'string_pred', 'tokens_pred', 'probs_tokens_pred', 'ground_truth', 'wer'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleurs_en = load_from_disk(os.path.join(predictions_confidence_path, 'fleurs_en'))\n",
    "fleurs_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display confidence colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "prediction &nbsp  &nbsp :  <text style=color:rgb(38,216,0)> Although</text><text style=color:rgb(2,252,0)> most</text><text style=color:rgb(1,253,0)> agencies</text><text style=color:rgb(0,254,0)> are</text><text style=color:rgb(0,254,0)> willing</text><text style=color:rgb(1,253,0)> to</text><text style=color:rgb(0,254,0)> take</text><text style=color:rgb(1,253,0)> on</text><text style=color:rgb(10,244,0)> most</text><text style=color:rgb(0,254,0)> regular</text><text style=color:rgb(13,241,0)> book</text><text style=color:rgb(0,254,0)>ings</text><text style=color:rgb(62,192,0)>,</text><text style=color:rgb(2,252,0)> many</text><text style=color:rgb(9,245,0)> agents</text><text style=color:rgb(12,242,0)> specialize</text><text style=color:rgb(1,253,0)> in</text><text style=color:rgb(1,253,0)> particular</text><text style=color:rgb(0,254,0)> types</text><text style=color:rgb(0,255,0)> of</text><text style=color:rgb(0,254,0)> travel</text><text style=color:rgb(61,193,0)>,</text><text style=color:rgb(1,253,0)> budget</text><text style=color:rgb(4,250,0)> ranges</text><text style=color:rgb(255,0,0)> or</text><text style=color:rgb(3,251,0)> destinations</text><text style=color:rgb(19,235,0)>.</text><br>ground truth : Although most agencies are willing to take on most regular bookings, many agents specialise in particular types of travel, budget ranges or destinations.<br>WER &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp: 0.0%<br><br>prediction &nbsp  &nbsp :  <text style=color:rgb(27,227,0)> The</text><text style=color:rgb(106,148,0)> believer</text><text style=color:rgb(0,254,0)> seeks</text><text style=color:rgb(3,251,0)> a</text><text style=color:rgb(0,254,0)> direct</text><text style=color:rgb(0,254,0)> experience</text><text style=color:rgb(255,0,0)> intuition</text><text style=color:rgb(6,248,0)> or</text><text style=color:rgb(0,255,0)> insight</text><text style=color:rgb(2,252,0)> into</text><text style=color:rgb(47,207,0)> divine</text><text style=color:rgb(0,254,0)> reality</text><text style=color:rgb(23,231,0)>,</text><text style=color:rgb(7,247,0)> the</text><text style=color:rgb(171,83,0)> deity</text><text style=color:rgb(174,80,0)>,</text><text style=color:rgb(4,250,0)> or</text><text style=color:rgb(10,244,0)> de</text><text style=color:rgb(0,254,0)>ities</text><text style=color:rgb(18,236,0)>.</text><br>ground truth : The believer seeks a direct experience, intuition, or insight into divine reality/the deity or dieties.<br>WER &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp: 6.2%<br><br>prediction &nbsp  &nbsp :  <text style=color:rgb(255,0,0)> Some</text><text style=color:rgb(10,244,0)> people</text><text style=color:rgb(10,244,0)> believe</text><text style=color:rgb(24,230,0)> that</text><text style=color:rgb(35,219,0)> experiencing</text><text style=color:rgb(29,225,0)> many</text><text style=color:rgb(35,219,0)> artific</text><text style=color:rgb(0,255,0)>ially</text><text style=color:rgb(35,219,0)> induced</text><text style=color:rgb(43,211,0)> luc</text><text style=color:rgb(4,250,0)>id</text><text style=color:rgb(21,233,0)> dreams</text><text style=color:rgb(185,69,0)> often</text><text style=color:rgb(11,243,0)> enough</text><text style=color:rgb(13,241,0)> can</text><text style=color:rgb(3,251,0)> be</text><text style=color:rgb(9,245,0)> very</text><text style=color:rgb(11,243,0)> exhausting</text><text style=color:rgb(224,30,0)>.</text><br>ground truth : Some people believe that experiencing many artificially induced lucid dreams often enough can be very exhausting.<br>WER &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp: 0.0%<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_print(html_display_confidence(fleurs_en, range(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3036025cbe2adbb32cae9758803a4d65b73631050a7460b737d800473c5124b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
