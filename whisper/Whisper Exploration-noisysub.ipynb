{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd337ad8",
   "metadata": {
    "id": "fd337ad8"
   },
   "source": [
    "# Whisper Model\n",
    "modified notebook by Sivan Ding (sd5397)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed621d7",
   "metadata": {
    "id": "0ed621d7"
   },
   "source": [
    "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
    "\n",
    "Code below adapted from [github repo](https://github.com/openai/whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeba0ae",
   "metadata": {
    "id": "efeba0ae"
   },
   "source": [
    "## Requirement\n",
    "Python 3.9.9 and PyTorch 1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Uezepu_hzPaE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3475,
     "status": "ok",
     "timestamp": 1665621892920,
     "user": {
      "displayName": "Alexandria Guo",
      "userId": "11397332379485803960"
     },
     "user_tz": 240
    },
    "id": "Uezepu_hzPaE",
    "outputId": "e36536ac-80bc-42ea-db9e-01a5036587ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorednoise in /opt/conda/lib/python3.7/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: ffmpeg in /opt/conda/lib/python3.7/site-packages (1.4)\r\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (0.12.1)\r\n",
      "Requirement already satisfied: jiwer in /opt/conda/lib/python3.7/site-packages (2.5.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from colorednoise) (1.19.5)\r\n",
      "Requirement already satisfied: torch==1.12.1 in /opt/conda/lib/python3.7/site-packages (from torchaudio) (1.12.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12.1->torchaudio) (4.1.1)\r\n",
      "Requirement already satisfied: levenshtein==0.20.2 in /opt/conda/lib/python3.7/site-packages (from jiwer) (0.20.2)\r\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from levenshtein==0.20.2->jiwer) (2.11.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install colorednoise ffmpeg torchaudio jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6567c13b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10865,
     "status": "ok",
     "timestamp": 1665620610648,
     "user": {
      "displayName": "Alexandria Guo",
      "userId": "11397332379485803960"
     },
     "user_tz": 240
    },
    "id": "6567c13b",
    "outputId": "0a48c983-fadb-4bfa-cc3a-b95085ced5bf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-m6zw9b__\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-m6zw9b__\n",
      "  Resolved https://github.com/openai/whisper.git to commit 9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (1.19.5)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (1.12.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (4.62.3)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (8.14.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (4.23.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (0.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (0.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (4.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.9.13)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (0.10.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->whisper==1.0) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.7.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "S-w-qciizG8O",
   "metadata": {
    "id": "S-w-qciizG8O"
   },
   "outputs": [],
   "source": [
    "# Julia's code\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import colorednoise as cn\n",
    "\n",
    "\n",
    "def add_noise(s, sample_rate=16000, noise_percentage_factor = .01, noise_type='white'):\n",
    "    # s: audio input (mono)\n",
    "    # sample rate: sample rate of s\n",
    "    # noise_percentage_factor, percentage scale of added noise added\n",
    "    # type: white, pink, brown\n",
    "\n",
    "    if noise_type == 'white':\n",
    "        beta = 0\n",
    "\n",
    "    elif noise_type == 'pink':\n",
    "        beta = 1\n",
    "\n",
    "    elif noise_type == 'brown':\n",
    "        beta = 2\n",
    "\n",
    "    noise = cn.powerlaw_psd_gaussian(beta, s.size)\n",
    "\n",
    "    noisy_s = s + noise * noise_percentage_factor\n",
    "\n",
    "    # output should be at 16kHz sample rate\n",
    "    if sample_rate != 16000:\n",
    "        noisy_s = librosa.resample(noisy_s, orig_sr = sample_rate, target_sr=16000)\n",
    "\n",
    "    return noisy_s\n",
    "\n",
    "\n",
    "def add_signals(s, back_s, sample_rate=16000, back_sample_rate=16000, noise_db=-12):\n",
    "    # s: audio input (mono)\n",
    "    # back_s: brckgrnd audio\n",
    "    # sample rate: sample rate of s\n",
    "    # noise_db: lower the backgrnd signal by noise_db db\n",
    "\n",
    "\n",
    "    # make sure both signals have same 16kHz sample rate\n",
    "    if sample_rate != 16000:\n",
    "        s = librosa.resample(s, orig_sr=sample_rate, target_sr=16000)\n",
    "\n",
    "    if back_sample_rate != 16000:\n",
    "        back_s = librosa.resample(back_s, orig_sr=back_sample_rate, target_sr=16000)\n",
    "\n",
    "    if s.size > back_s.size:\n",
    "        back_s = librosa.util.pad_center(back_s, size=s.size)\n",
    "\n",
    "    elif s.size < back_s.size:\n",
    "        s = librosa.util.pad_center(s, size=back_s.size)\n",
    "\n",
    "    # lower background signal by noise_db\n",
    "    noise_amp = librosa.db_to_amplitude(noise_db)\n",
    "    lower_back_s = back_s - noise_amp\n",
    "\n",
    "    # add background noise to sound clip\n",
    "    noisy_s = s + back_s\n",
    "\n",
    "    # output should be at 16kHz sample rate\n",
    "    return noisy_s\n",
    "\n",
    "\n",
    "def down_sample(s, sample_rate=16000, output_sr=8000):\n",
    "    # s: audio input (mono)\n",
    "    # sample rate: sample rate of s\n",
    "    # output_sr: output sample rate\n",
    "\n",
    "    # resample to output_sr\n",
    "    resampled_s = librosa.resample(s, orig_sr=sample_rate, target_sr=output_sr)\n",
    "\n",
    "    # then re-resample to 16000\n",
    "    noisy_s = librosa.resample(resampled_s, orig_sr=output_sr, target_sr=16000)\n",
    "\n",
    "    # output should be at 16kHz sample rate\n",
    "    return noisy_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58efc4bb",
   "metadata": {
    "id": "58efc4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29aeb2",
   "metadata": {
    "id": "ab29aeb2"
   },
   "source": [
    "# Base model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6f544",
   "metadata": {
    "id": "0ef6f544"
   },
   "source": [
    "### evaluation on LibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0adaf9d",
   "metadata": {
    "id": "d0adaf9d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# installing takes ~30 seconds\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        \n",
    "        return (mel, text)\n",
    "\n",
    "class LibriSpeechNoisy(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    MODIFIED: for added noise \n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "\n",
    "        audio_clean = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel_c = whisper.log_mel_spectrogram(audio_clean)\n",
    "\n",
    "        audio_noise = add_noise(audio.numpy(), sample_rate=sample_rate) # default white noise\n",
    "        audio_noise = torch.from_numpy(audio_noise.astype('float32'))\n",
    "        audio_noise = whisper.pad_or_trim(audio_noise.flatten()).to(self.device)\n",
    "        mel_n = whisper.log_mel_spectrogram(audio_noise)\n",
    "\n",
    "        audio_ds = down_sample(audio.numpy().flatten(), sample_rate=sample_rate) # default params\n",
    "        audio_ds = torch.from_numpy(audio_ds.astype('float32'))\n",
    "        audio_ds = whisper.pad_or_trim(audio_ds.flatten()).to(self.device)\n",
    "        mel_d = whisper.log_mel_spectrogram(audio_ds)\n",
    "        \n",
    "        return (mel_c, mel_n, mel_d, text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf1fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriSpeechNoisy(\"test-clean\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "577268b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1878,
     "status": "ok",
     "timestamp": 1665627120687,
     "user": {
      "displayName": "Alexandria Guo",
      "userId": "11397332379485803960"
     },
     "user_tz": 240
    },
    "id": "577268b3",
    "outputId": "9acba9a1-b834-40aa-8812-dd76a5970329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 71,825,408 parameters.\n",
      "CPU times: user 1.81 s, sys: 176 ms, total: 1.99 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load base model and review\n",
    "model = whisper.load_model(\"base.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32e7f68",
   "metadata": {
    "id": "d32e7f68"
   },
   "outputs": [],
   "source": [
    "# predict without timestamps for short-form transcription\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True, fp16 = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae58fd06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "723136acded84f0b9732b36686ae499d",
      "48092cbcdba545c78981b9a98f18c952",
      "a4f9e4c96272422e9a25e7057dbcef50",
      "f36a2a32b1904fe0a1fa6ec6f71f2959",
      "f8fa0d556df149b580df93230603ca18",
      "9ce122e66b33457b8c94de6a0a08a2dd",
      "53e2a998d23247e68676de5ba64c5d8a",
      "39c4af0ff4b542e8a9bfdcc9bda65a1e",
      "ed10533543dd4f0994088f97899aeb50",
      "ec3ba4a418da4fbbaf7ed341b76a4494",
      "488cf9010cf940bcaacf00bc25827357"
     ]
    },
    "id": "ae58fd06",
    "outputId": "6ae8dfa7-be25-4221-ea97-01261536108f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5965b2034ae74ca385bedd0c61be61ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 48s, sys: 9min 46s, total: 50min 35s\n",
      "Wall time: 41min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hypotheses_c = []\n",
    "hypotheses_n = []\n",
    "hypotheses_d = []\n",
    "references = []\n",
    "\n",
    "for i, (mels_c, mels_n, mels_d, texts) in enumerate(tqdm(loader)):\n",
    "    results_c = model.decode(mels_c, options)\n",
    "    hypotheses_c.extend([result.text for result in results_c])\n",
    "    results_n = model.decode(mels_n, options)\n",
    "    hypotheses_n.extend([result.text for result in results_n])\n",
    "    results_d = model.decode(mels_d, options)\n",
    "    hypotheses_d.extend([result.text for result in results_d])\n",
    "    \n",
    "    references.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abeb9a22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "abeb9a22",
    "outputId": "1c72d25a-3e87-4c60-a8d1-1da9d2f73bd7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect on testing results\n",
    "data_clean = pd.DataFrame(dict(hypothesis=hypotheses_c, reference=references))\n",
    "data_noise = pd.DataFrame(dict(hypothesis=hypotheses_n, reference=references))\n",
    "data_downs = pd.DataFrame(dict(hypothesis=hypotheses_d, reference=references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec43b4da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "ec43b4da",
    "outputId": "f2089bc9-f535-441e-f192-26e52ae82b5e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.26 s, sys: 35.1 ms, total: 4.29 s\n",
      "Wall time: 4.36 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis_clean</th>\n",
       "      <th>reference_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuffered into you, his belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "      <td>stuffered into you his belly counseled him</td>\n",
       "      <td>stuff it into you his belly counseled him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall the yellow lamps would l...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Bertie, any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10. Fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>Oh, to shoot my soul's full meaning into futur...</td>\n",
       "      <td>OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>Then I, long tried by natural ills, received t...</td>\n",
       "      <td>THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>I love thee freely as men strive for right. I ...</td>\n",
       "      <td>I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>I love thee with the passion put to use, in my...</td>\n",
       "      <td>I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>I love thee with the love I seemed to lose wit...</td>\n",
       "      <td>I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...</td>\n",
       "      <td>i love thee with the love i seemed to lose wit...</td>\n",
       "      <td>i love thee with a love i seemed to lose with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2620 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hypothesis  \\\n",
       "0     He hoped there would be stew for dinner, turni...   \n",
       "1          Stuffered into you, his belly counseled him.   \n",
       "2     After early nightfall the yellow lamps would l...   \n",
       "3                  Hello Bertie, any good in your mind?   \n",
       "4     Number 10. Fresh Nelly is waiting on you. Good...   \n",
       "...                                                 ...   \n",
       "2615  Oh, to shoot my soul's full meaning into futur...   \n",
       "2616  Then I, long tried by natural ills, received t...   \n",
       "2617  I love thee freely as men strive for right. I ...   \n",
       "2618  I love thee with the passion put to use, in my...   \n",
       "2619  I love thee with the love I seemed to lose wit...   \n",
       "\n",
       "                                              reference  \\\n",
       "0     HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...   \n",
       "1            STUFF IT INTO YOU HIS BELLY COUNSELLED HIM   \n",
       "2     AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...   \n",
       "3                    HELLO BERTIE ANY GOOD IN YOUR MIND   \n",
       "4     NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...   \n",
       "...                                                 ...   \n",
       "2615  OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...   \n",
       "2616  THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...   \n",
       "2617  I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...   \n",
       "2618  I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...   \n",
       "2619  I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...   \n",
       "\n",
       "                                       hypothesis_clean  \\\n",
       "0     he hoped there would be stew for dinner turnip...   \n",
       "1            stuffered into you his belly counseled him   \n",
       "2     after early nightfall the yellow lamps would l...   \n",
       "3                    hello bertie any good in your mind   \n",
       "4     number 10 fresh nelly is waiting on you good n...   \n",
       "...                                                 ...   \n",
       "2615  0 to shoot my soul is full meaning into future...   \n",
       "2616  then i long tried by natural ills received the...   \n",
       "2617  i love thee freely as men strive for right i l...   \n",
       "2618  i love thee with the passion put to use in my ...   \n",
       "2619  i love thee with the love i seemed to lose wit...   \n",
       "\n",
       "                                        reference_clean  \n",
       "0     he hoped there would be stew for dinner turnip...  \n",
       "1             stuff it into you his belly counseled him  \n",
       "2     after early nightfall the yellow lamps would l...  \n",
       "3                    hello bertie any good in your mind  \n",
       "4     number 10 fresh nelly is waiting on you good n...  \n",
       "...                                                 ...  \n",
       "2615  0 to shoot my soul is full meaning into future...  \n",
       "2616  then i long tried by natural ills received the...  \n",
       "2617  i love thee freely as men strive for right i l...  \n",
       "2618  i love thee with the passion put to use in my ...  \n",
       "2619  i love thee with a love i seemed to lose with ...  \n",
       "\n",
       "[2620 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import jiwer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "def clean_text(normalizer, pred_dict):\n",
    "  pred_dict[\"hypothesis_clean\"] = [normalizer(text) for text in pred_dict[\"hypothesis\"]]\n",
    "  pred_dict[\"reference_clean\"] = [normalizer(text) for text in pred_dict[\"reference\"]]\n",
    "  return(pred_dict)\n",
    "\n",
    "normalizer = EnglishTextNormalizer()\n",
    "data_clean = clean_text(normalizer, data_clean)\n",
    "data_noise = clean_text(normalizer, data_noise)\n",
    "data_downs = clean_text(normalizer, data_downs)\n",
    "\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e9c609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042c7fbcdc104cd3a9e6292da7416c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/314M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = LibriSpeech(\"test-other\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99d51285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75265519c4484b61aaab7271ee190e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 38s, sys: 3min 25s, total: 13min 4s\n",
      "Wall time: 11min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "for i, (mels, texts) in enumerate(tqdm(loader)):\n",
    "    results = model.decode(mels, options)\n",
    "    hypotheses.extend([result.text for result in results])\n",
    "    references.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b55d361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's iron, they say, in all our blood, and ...</td>\n",
       "      <td>THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Margaret said Mr. Hale as he returned from sho...</td>\n",
       "      <td>MARGARET SAID MISTER HALE AS HE RETURNED FROM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You don't mean that you thought me so silly.</td>\n",
       "      <td>YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I really like that account of himself, better ...</td>\n",
       "      <td>I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His statement of having been a shop boy was th...</td>\n",
       "      <td>HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>Poor Isaac was hurried off accordingly, and ex...</td>\n",
       "      <td>POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>The assurance that she possessed some friend i...</td>\n",
       "      <td>THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>She gazed accordingly upon a scene which might...</td>\n",
       "      <td>SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>At his feet was placed at the table occupied b...</td>\n",
       "      <td>AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>The preceptors, of whom there were four presen...</td>\n",
       "      <td>THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hypothesis  \\\n",
       "0     There's iron, they say, in all our blood, and ...   \n",
       "1     Margaret said Mr. Hale as he returned from sho...   \n",
       "2          You don't mean that you thought me so silly.   \n",
       "3     I really like that account of himself, better ...   \n",
       "4     His statement of having been a shop boy was th...   \n",
       "...                                                 ...   \n",
       "2934  Poor Isaac was hurried off accordingly, and ex...   \n",
       "2935  The assurance that she possessed some friend i...   \n",
       "2936  She gazed accordingly upon a scene which might...   \n",
       "2937  At his feet was placed at the table occupied b...   \n",
       "2938  The preceptors, of whom there were four presen...   \n",
       "\n",
       "                                              reference  \n",
       "0     THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...  \n",
       "1     MARGARET SAID MISTER HALE AS HE RETURNED FROM ...  \n",
       "2           YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY  \n",
       "3     I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...  \n",
       "4     HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...  \n",
       "...                                                 ...  \n",
       "2934  POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...  \n",
       "2935  THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...  \n",
       "2936  SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...  \n",
       "2937  AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...  \n",
       "2938  THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...  \n",
       "\n",
       "[2939 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6db182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 0 ns, total: 1.74 s\n",
      "Wall time: 1.74 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis_clean</th>\n",
       "      <th>reference_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's iron, they say, in all our blood, and ...</td>\n",
       "      <td>THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...</td>\n",
       "      <td>there is iron they say in all our blood and a ...</td>\n",
       "      <td>there is iron they say in all our blood and a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Margaret said Mr. Hale as he returned from sho...</td>\n",
       "      <td>MARGARET SAID MISTER HALE AS HE RETURNED FROM ...</td>\n",
       "      <td>margaret said mister hale as he returned from ...</td>\n",
       "      <td>margaret said mister hale as he returned from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You don't mean that you thought me so silly.</td>\n",
       "      <td>YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY</td>\n",
       "      <td>you do not mean that you thought me so silly</td>\n",
       "      <td>you do not mean that you thought me so silly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I really like that account of himself, better ...</td>\n",
       "      <td>I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...</td>\n",
       "      <td>i really like that account of himself better t...</td>\n",
       "      <td>i really liked that account of himself better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His statement of having been a shop boy was th...</td>\n",
       "      <td>HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...</td>\n",
       "      <td>his statement of having been a shop boy was th...</td>\n",
       "      <td>his statement of having been a shop boy was th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>Poor Isaac was hurried off accordingly, and ex...</td>\n",
       "      <td>POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...</td>\n",
       "      <td>poor isaac was hurried off accordingly and exp...</td>\n",
       "      <td>poor isaac was hurried off accordingly and exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>The assurance that she possessed some friend i...</td>\n",
       "      <td>THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...</td>\n",
       "      <td>the assurance that she possessed some friend i...</td>\n",
       "      <td>the assurance that she possessed some friend i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>She gazed accordingly upon a scene which might...</td>\n",
       "      <td>SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...</td>\n",
       "      <td>she gazed accordingly upon a scene which might...</td>\n",
       "      <td>she gazed accordingly upon a scene which might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>At his feet was placed at the table occupied b...</td>\n",
       "      <td>AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...</td>\n",
       "      <td>at his feet was placed at the table occupied b...</td>\n",
       "      <td>at his feet was placed a table occupied by 2 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>The preceptors, of whom there were four presen...</td>\n",
       "      <td>THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...</td>\n",
       "      <td>the preceptors of whom there were 4 present oc...</td>\n",
       "      <td>the preceptors of whom there were 4 present oc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hypothesis  \\\n",
       "0     There's iron, they say, in all our blood, and ...   \n",
       "1     Margaret said Mr. Hale as he returned from sho...   \n",
       "2          You don't mean that you thought me so silly.   \n",
       "3     I really like that account of himself, better ...   \n",
       "4     His statement of having been a shop boy was th...   \n",
       "...                                                 ...   \n",
       "2934  Poor Isaac was hurried off accordingly, and ex...   \n",
       "2935  The assurance that she possessed some friend i...   \n",
       "2936  She gazed accordingly upon a scene which might...   \n",
       "2937  At his feet was placed at the table occupied b...   \n",
       "2938  The preceptors, of whom there were four presen...   \n",
       "\n",
       "                                              reference  \\\n",
       "0     THERE'S IRON THEY SAY IN ALL OUR BLOOD AND A G...   \n",
       "1     MARGARET SAID MISTER HALE AS HE RETURNED FROM ...   \n",
       "2           YOU DON'T MEAN THAT YOU THOUGHT ME SO SILLY   \n",
       "3     I REALLY LIKED THAT ACCOUNT OF HIMSELF BETTER ...   \n",
       "4     HIS STATEMENT OF HAVING BEEN A SHOP BOY WAS TH...   \n",
       "...                                                 ...   \n",
       "2934  POOR ISAAC WAS HURRIED OFF ACCORDINGLY AND EXP...   \n",
       "2935  THE ASSURANCE THAT SHE POSSESSED SOME FRIEND I...   \n",
       "2936  SHE GAZED ACCORDINGLY UPON A SCENE WHICH MIGHT...   \n",
       "2937  AT HIS FEET WAS PLACED A TABLE OCCUPIED BY TWO...   \n",
       "2938  THE PRECEPTORS OF WHOM THERE WERE FOUR PRESENT...   \n",
       "\n",
       "                                       hypothesis_clean  \\\n",
       "0     there is iron they say in all our blood and a ...   \n",
       "1     margaret said mister hale as he returned from ...   \n",
       "2          you do not mean that you thought me so silly   \n",
       "3     i really like that account of himself better t...   \n",
       "4     his statement of having been a shop boy was th...   \n",
       "...                                                 ...   \n",
       "2934  poor isaac was hurried off accordingly and exp...   \n",
       "2935  the assurance that she possessed some friend i...   \n",
       "2936  she gazed accordingly upon a scene which might...   \n",
       "2937  at his feet was placed at the table occupied b...   \n",
       "2938  the preceptors of whom there were 4 present oc...   \n",
       "\n",
       "                                        reference_clean  \n",
       "0     there is iron they say in all our blood and a ...  \n",
       "1     margaret said mister hale as he returned from ...  \n",
       "2          you do not mean that you thought me so silly  \n",
       "3     i really liked that account of himself better ...  \n",
       "4     his statement of having been a shop boy was th...  \n",
       "...                                                 ...  \n",
       "2934  poor isaac was hurried off accordingly and exp...  \n",
       "2935  the assurance that she possessed some friend i...  \n",
       "2936  she gazed accordingly upon a scene which might...  \n",
       "2937  at his feet was placed a table occupied by 2 s...  \n",
       "2938  the preceptors of whom there were 4 present oc...  \n",
       "\n",
       "[2939 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = clean_text(normalizer, data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd6d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean WER: 4.27 %\n",
      "White noise WER: 6.06 %\n",
      "Downsampled WER: 4.79 %\n",
      "Other WER: 10.36 %\n"
     ]
    }
   ],
   "source": [
    "wer_c = jiwer.wer(list(data_clean[\"reference_clean\"]), list(data_clean[\"hypothesis_clean\"]))\n",
    "wer_n = jiwer.wer(list(data_noise[\"reference_clean\"]), list(data_noise[\"hypothesis_clean\"]))\n",
    "wer_d = jiwer.wer(list(data_downs[\"reference_clean\"]), list(data_downs[\"hypothesis_clean\"]))\n",
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"Clean WER: {wer_c * 100:.2f} %\")\n",
    "print(f\"White noise WER: {wer_n * 100:.2f} %\")\n",
    "print(f\"Downsampled WER: {wer_d * 100:.2f} %\")\n",
    "print(f\"Other WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f119bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER% for Wav2Vec and Whisper on LibriSpeech test under different conditions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Data</th>\n",
       "      <th>Wav2Vec2-base-960h</th>\n",
       "      <th>Whisper-base.en</th>\n",
       "      <th>degradation ratio to clean set(Wav2Vec2)</th>\n",
       "      <th>degradation ratio to clean set(Whisper)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ls-test-clean</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ls-test-other</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ls-test-clean, noisy</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ls-test-clean, downsampled</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Test Data  Wav2Vec2-base-960h  Whisper-base.en  \\\n",
       "0               ls-test-clean                 3.4              4.3   \n",
       "1               ls-test-other                 9.3             10.4   \n",
       "2        ls-test-clean, noisy                 8.3              6.1   \n",
       "3  ls-test-clean, downsampled                 4.2              4.8   \n",
       "\n",
       "   degradation ratio to clean set(Wav2Vec2)  \\\n",
       "0                                      0.00   \n",
       "1                                      1.73   \n",
       "2                                      1.44   \n",
       "3                                      0.24   \n",
       "\n",
       "   degradation ratio to clean set(Whisper)  \n",
       "0                                     0.00  \n",
       "1                                     1.42  \n",
       "2                                     0.46  \n",
       "3                                     0.12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare initial results with Wav2Vec2\n",
    "# results from https://github.com/anhvung/Capstone-Audio-Transcription/blob/wav2vec/wav2vec/wav2vec_noisy.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# pd.set_option(\"display.precision\", 5)\n",
    "comparison = pd.DataFrame({'Test Data': ['ls-test-clean', 'ls-test-other', 'ls-test-clean, noisy', 'ls-test-clean, downsampled'],\n",
    "                           'Wav2Vec2-base-960h':[3.4, 9.3, 8.3, 4.2],\n",
    "                          'Whisper-base.en': [4.3, 10.4, 6.1, 4.8],\n",
    "                           'degradation ratio to clean set(Wav2Vec2)': [0.00, 1.73, 1.44, 0.24],\n",
    "                           'degradation ratio to clean set(Whisper)': [0.00, 1.42, 0.46, 0.12],\n",
    "                           })\n",
    "# comparison.style.set_caption(\"WER% for Wav2Vec and Whisper under different conditions\")\n",
    "print(\"WER% for Wav2Vec and Whisper on LibriSpeech test under different conditions\")\n",
    "display(comparison)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "39c4af0ff4b542e8a9bfdcc9bda65a1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48092cbcdba545c78981b9a98f18c952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ce122e66b33457b8c94de6a0a08a2dd",
      "placeholder": "​",
      "style": "IPY_MODEL_53e2a998d23247e68676de5ba64c5d8a",
      "value": "  0%"
     }
    },
    "488cf9010cf940bcaacf00bc25827357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53e2a998d23247e68676de5ba64c5d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "723136acded84f0b9732b36686ae499d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48092cbcdba545c78981b9a98f18c952",
       "IPY_MODEL_a4f9e4c96272422e9a25e7057dbcef50",
       "IPY_MODEL_f36a2a32b1904fe0a1fa6ec6f71f2959"
      ],
      "layout": "IPY_MODEL_f8fa0d556df149b580df93230603ca18"
     }
    },
    "9ce122e66b33457b8c94de6a0a08a2dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4f9e4c96272422e9a25e7057dbcef50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39c4af0ff4b542e8a9bfdcc9bda65a1e",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed10533543dd4f0994088f97899aeb50",
      "value": 0
     }
    },
    "ec3ba4a418da4fbbaf7ed341b76a4494": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed10533543dd4f0994088f97899aeb50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f36a2a32b1904fe0a1fa6ec6f71f2959": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec3ba4a418da4fbbaf7ed341b76a4494",
      "placeholder": "​",
      "style": "IPY_MODEL_488cf9010cf940bcaacf00bc25827357",
      "value": " 0/164 [00:00&lt;?, ?it/s]"
     }
    },
    "f8fa0d556df149b580df93230603ca18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
